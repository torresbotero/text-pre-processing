{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from experiments_core import run_one_comb_experiment\n",
    "from experiments_core import norm_repeated_letters\n",
    "from experiments_core import stem_tokens\n",
    "from experiments_core import lemmatizer\n",
    "from experiments_core import save_excel_comb_results\n",
    "from experiments_core import RepeatReplacer\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "import xlsxwriter\n",
    "\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'experiments_core' from '/home/ctorres9/EAFIT/trabajogrado/experiments/experiments_core.py'>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import sys\n",
    "importlib.reload(sys.modules[run_one_comb_experiment.__module__])\n",
    "importlib.reload(sys.modules[norm_repeated_letters.__module__])\n",
    "importlib.reload(sys.modules[stem_tokens.__module__])\n",
    "importlib.reload(sys.modules[lemmatizer.__module__])\n",
    "importlib.reload(sys.modules[save_excel_comb_results.__module__])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      tweetid          user               content  \\\n",
      "count                   60798         60798                 60798   \n",
      "unique                  60798           158                 60405   \n",
      "top      148488915765047296,0  mariviromero  Buenos días a todos!   \n",
      "freq                        1          7138                   111   \n",
      "\n",
      "                       date   lang polarity  topic  \n",
      "count                 60798  60798    60798  60798  \n",
      "unique                60510      1        6     10  \n",
      "top     2012-01-01T00:00:16     es     NONE  otros  \n",
      "freq                      4  60798    21416  28189  \n",
      "                 tweetid            user  \\\n",
      "0   142378325086715904,0     jesusmarana   \n",
      "1   142379080808013824,0       EvaORegan   \n",
      "2   142379173120442368,0  LosadaPescador   \n",
      "3   142379815708803072,0    mgilguerrero   \n",
      "4   142381190123499520,0  pedroj_ramirez   \n",
      "\n",
      "                                             content                 date  \\\n",
      "0  Portada 'Público', viernes. Fabra al banquillo...  2011-12-02T00:03:32   \n",
      "1  Grande! RT @veronicacalderon \"El periodista es...  2011-12-02T00:06:32   \n",
      "2  Gonzalo Altozano tras la presentación de su li...  2011-12-02T00:06:55   \n",
      "3  Mañana en Gaceta: TVE, la que pagamos tú y yo,...  2011-12-02T00:09:28   \n",
      "4  Qué envidia “@mfcastineiras: Pedro mañana x la...  2011-12-02T00:14:55   \n",
      "\n",
      "  lang polarity            topic  \n",
      "0   es        N         política  \n",
      "1   es     NONE         política  \n",
      "2   es       P+            otros  \n",
      "3   es        N  entretenimiento  \n",
      "4   es     NONE            otros  \n"
     ]
    }
   ],
   "source": [
    "file_path = 'data/TweetsPolaridadSEPLN.csv'\n",
    "original_tweets_df = pd.read_csv(file_path, index_col=None, header=0, sep='\\t')\n",
    "print(original_tweets_df.describe())\n",
    "print(original_tweets_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  content  polarity\n",
      "count                                               38077     38077\n",
      "unique                                              37926         2\n",
      "top     ¡Noticias descombacantes! está disponible! htt...  positive\n",
      "freq                                                   63     22233\n",
      "                                             content  polarity\n",
      "0  Dado q la deuda privada es superior a la publi...  negative\n",
      "1  TEPCO inyecta nitrógeno en los reactores de Fu...  negative\n",
      "2  “@Declaracion: «Cualquier injusticia contra un...  negative\n",
      "3  ¡Qué estrés!, la presidenta de la diputación d...  negative\n",
      "4  Hoy entrego mi credencial en el Congreso. Una ...  negative\n"
     ]
    }
   ],
   "source": [
    "strong_negative_tweets = original_tweets_df[original_tweets_df.polarity == 'N+'][['content','polarity']]\n",
    "standar_negative_tweets = original_tweets_df[original_tweets_df.polarity == 'N'][['content','polarity']]\n",
    "\n",
    "strong_positive_tweets = original_tweets_df[original_tweets_df.polarity == 'P+'][['content','polarity']]\n",
    "standar_positive_tweets = original_tweets_df[original_tweets_df.polarity == 'P'][['content','polarity']]\n",
    "\n",
    "negative_tweets = pd.concat([strong_negative_tweets,standar_negative_tweets], ignore_index=True)\n",
    "positive_tweets = pd.concat([strong_positive_tweets,standar_positive_tweets], ignore_index=True)\n",
    "\n",
    "negative_tweets.polarity = \"negative\"\n",
    "positive_tweets.polarity = \"positive\"\n",
    "\n",
    "total_tweets = pd.concat([negative_tweets,positive_tweets], ignore_index=True)\n",
    "print(total_tweets.describe())\n",
    "print(total_tweets.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data_content = total_tweets.content\n",
    "total_data_target = total_tweets.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(total_data_content, \n",
    "                                                    total_data_target, \n",
    "                                                    test_size=0.3, \n",
    "                                                    random_state=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positivos entrenamiento: 15552\n",
      "Negativos entrenamiento: 11101\n",
      "Positivos pruebas: 6681\n",
      "Negativos pruebas: 4743\n"
     ]
    }
   ],
   "source": [
    "print(\"Positivos entrenamiento:\", len(y_train[y_train == 'positive']))\n",
    "print(\"Negativos entrenamiento:\", len(y_train[y_train == 'negative']))\n",
    "print(\"Positivos pruebas:\", len(y_test[y_test == 'positive']))\n",
    "print(\"Negativos pruebas:\", len(y_test[y_test == 'negative']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "spanish_stopwords = stopwords.words('spanish')\n",
    "stemmer = SnowballStemmer('spanish')\n",
    "replacer = RepeatReplacer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combinaciones de experimentos para tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los siguientes son los resultados de las combinaciones entre los diferentes metodos de limpieza y ponderacion en la representacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_processing_tasks = ['stop_words','stemming','lemmatization','urls','norm_letters','pruning10','pruning5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_the_tasks = []\n",
    "for r in range(1, len(pre_processing_tasks) + 1):\n",
    "    all_the_tasks = all_the_tasks + list(itertools.combinations(pre_processing_tasks, r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_the_tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\n",
      "56\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "tasks_to_remove = []\n",
    "for comb in all_the_tasks:\n",
    "    if (('stemming' in comb) and ('lemmatization' in comb)) or (('pruning10' in comb) and ('pruning5' in comb)):\n",
    "        #all_the_tasks.remove(comb)\n",
    "        tasks_to_remove.append(comb)\n",
    "        count += 1\n",
    "print(count)\n",
    "print(len(tasks_to_remove))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for task in tasks_to_remove:\n",
    "    all_the_tasks.remove(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_the_tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_test = [('stop_words'),('stemming'), ('lemmatization'), ('urls'), ('norm_letters'), ('pruning10'), ('pruning5')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_types_weighting_types = [{'clf_name': 'Bayesiano', 'clf_type': MultinomialNB(), \n",
    "                              'weighting_type': 'TF', 'optimal_parameters': {'alpha': [3]}, 'random_state': 40},\n",
    "                             {'clf_name': 'Bayesiano', 'clf_type': MultinomialNB(), \n",
    "                              'weighting_type': 'TF-IDF', 'optimal_parameters': {'alpha': [1]}, 'random_state': 30},\n",
    "                             {'clf_name': 'Bayesiano', 'clf_type': MultinomialNB(), \n",
    "                              'weighting_type': 'Binario', 'optimal_parameters': {'alpha': [3]}, 'random_state': 40},\n",
    "                             \n",
    "#                              {'clf_name': 'SVM_radial', 'clf_type': SVC(), \n",
    "#                               'weighting_type': 'TF', 'optimal_parameters': {'kernel': ['rbf'], 'gamma': [0.001], 'C': [100]}, 'random_state': 30},\n",
    "#                              {'clf_name': 'SVM_radial', 'clf_type': SVC(), \n",
    "#                               'weighting_type': 'TF-IDF', 'optimal_parameters': {'kernel': ['rbf'], 'gamma': [0.001], 'C': [1000]}, 'random_state': 10},\n",
    "#                              {'clf_name': 'SVM_radial', 'clf_type': SVC(), \n",
    "#                               'weighting_type': 'Binario', 'optimal_parameters': {'kernel': ['rbf'], 'gamma': [0.001], 'C': [100]}, 'random_state': 30},\n",
    "                            \n",
    "                             {'clf_name': 'SVM_lineal', 'clf_type': LinearSVC(), \n",
    "                              'weighting_type': 'TF', 'optimal_parameters': {'C': [0.1]}, 'random_state': 40},\n",
    "                             {'clf_name': 'SVM_lineal', 'clf_type': LinearSVC(), \n",
    "                              'weighting_type': 'TF-IDF', 'optimal_parameters': {'C': [1]}, 'random_state': 30},\n",
    "                             {'clf_name': 'SVM_lineal', 'clf_type': LinearSVC(), \n",
    "                              'weighting_type': 'Binario', 'optimal_parameters': {'C': [0.1]}, 'random_state': 40},\n",
    "                            \n",
    "                             {'clf_name': 'Reg_Log', 'clf_type': LogisticRegression(), \n",
    "                              'weighting_type': 'TF', 'optimal_parameters': {'C': [1]}, 'random_state': 40},\n",
    "                             {'clf_name': 'Reg_Log', 'clf_type': LogisticRegression(), \n",
    "                              'weighting_type': 'TF-IDF', 'optimal_parameters': {'C': [10]}, 'random_state': 40},\n",
    "                             {'clf_name': 'Reg_Log', 'clf_type': LogisticRegression(), \n",
    "                              'weighting_type': 'Binario', 'optimal_parameters': {'C': [1]}, 'random_state': 40}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'clf_name': 'Bayesiano',\n",
       "  'clf_type': MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),\n",
       "  'weighting_type': 'TF',\n",
       "  'optimal_parameters': {'alpha': [3]},\n",
       "  'random_state': 40},\n",
       " {'clf_name': 'Bayesiano',\n",
       "  'clf_type': MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),\n",
       "  'weighting_type': 'TF-IDF',\n",
       "  'optimal_parameters': {'alpha': [1]},\n",
       "  'random_state': 30},\n",
       " {'clf_name': 'Bayesiano',\n",
       "  'clf_type': MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),\n",
       "  'weighting_type': 'Binario',\n",
       "  'optimal_parameters': {'alpha': [3]},\n",
       "  'random_state': 40},\n",
       " {'clf_name': 'SVM_lineal',\n",
       "  'clf_type': LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "       intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "       multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "       verbose=0),\n",
       "  'weighting_type': 'TF',\n",
       "  'optimal_parameters': {'C': [0.1]},\n",
       "  'random_state': 40},\n",
       " {'clf_name': 'SVM_lineal',\n",
       "  'clf_type': LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "       intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "       multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "       verbose=0),\n",
       "  'weighting_type': 'TF-IDF',\n",
       "  'optimal_parameters': {'C': [1]},\n",
       "  'random_state': 30},\n",
       " {'clf_name': 'SVM_lineal',\n",
       "  'clf_type': LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "       intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "       multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "       verbose=0),\n",
       "  'weighting_type': 'Binario',\n",
       "  'optimal_parameters': {'C': [0.1]},\n",
       "  'random_state': 40},\n",
       " {'clf_name': 'Reg_Log',\n",
       "  'clf_type': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False),\n",
       "  'weighting_type': 'TF',\n",
       "  'optimal_parameters': {'C': [1]},\n",
       "  'random_state': 40},\n",
       " {'clf_name': 'Reg_Log',\n",
       "  'clf_type': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False),\n",
       "  'weighting_type': 'TF-IDF',\n",
       "  'optimal_parameters': {'C': [10]},\n",
       "  'random_state': 40},\n",
       " {'clf_name': 'Reg_Log',\n",
       "  'clf_type': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False),\n",
       "  'weighting_type': 'Binario',\n",
       "  'optimal_parameters': {'C': [1]},\n",
       "  'random_state': 40}]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_types_weighting_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bayesiano_TF('stop_words',)\n",
      "train time: 6.414s\n",
      "Bayesiano_TF('stemming',)\n",
      "train time: 6.520s\n",
      "Bayesiano_TF('lemmatization',)\n",
      "train time: 6.475s\n",
      "Bayesiano_TF('urls',)\n",
      "train time: 6.537s\n",
      "Bayesiano_TF('norm_letters',)\n",
      "train time: 8.871s\n",
      "Bayesiano_TF('pruning10',)\n",
      "train time: 9.168s\n",
      "Bayesiano_TF('pruning5',)\n",
      "train time: 9.516s\n",
      "Bayesiano_TF('stop_words', 'stemming')\n",
      "train time: 9.502s\n",
      "Bayesiano_TF('stop_words', 'lemmatization')\n",
      "train time: 9.318s\n",
      "Bayesiano_TF('stop_words', 'urls')\n",
      "train time: 10.280s\n",
      "Bayesiano_TF('stop_words', 'norm_letters')\n",
      "train time: 9.794s\n",
      "Bayesiano_TF('stop_words', 'pruning10')\n",
      "train time: 10.011s\n",
      "Bayesiano_TF('stop_words', 'pruning5')\n",
      "train time: 10.194s\n",
      "Bayesiano_TF('stemming', 'urls')\n",
      "train time: 10.242s\n",
      "Bayesiano_TF('stemming', 'norm_letters')\n",
      "train time: 10.025s\n",
      "Bayesiano_TF('stemming', 'pruning10')\n",
      "train time: 10.615s\n",
      "Bayesiano_TF('stemming', 'pruning5')\n",
      "train time: 10.274s\n",
      "Bayesiano_TF('lemmatization', 'urls')\n",
      "train time: 10.887s\n",
      "Bayesiano_TF('lemmatization', 'norm_letters')\n",
      "train time: 11.033s\n",
      "Bayesiano_TF('stop_words', 'stemming', 'urls')\n",
      "train time: 11.394s\n",
      "Bayesiano_TF('stop_words', 'stemming', 'norm_letters')\n",
      "train time: 11.319s\n",
      "Bayesiano_TF('stop_words', 'stemming', 'pruning10')\n",
      "train time: 11.251s\n",
      "Bayesiano_TF('stop_words', 'stemming', 'pruning5')\n",
      "train time: 11.235s\n",
      "Bayesiano_TF('stop_words', 'lemmatization', 'urls')\n",
      "train time: 11.988s\n",
      "Bayesiano_TF('stop_words', 'lemmatization', 'norm_letters')\n",
      "train time: 11.307s\n",
      "Bayesiano_TF('stop_words', 'lemmatization', 'pruning10')\n",
      "train time: 12.140s\n",
      "Bayesiano_TF('stop_words', 'lemmatization', 'pruning5')\n",
      "train time: 11.991s\n",
      "Bayesiano_TF('stop_words', 'urls', 'norm_letters')\n",
      "train time: 12.008s\n",
      "Bayesiano_TF('stop_words', 'urls', 'pruning10')\n",
      "train time: 12.371s\n",
      "Bayesiano_TF('stop_words', 'urls', 'pruning5')\n",
      "train time: 12.323s\n",
      "Bayesiano_TF('stop_words', 'norm_letters', 'pruning10')\n",
      "train time: 12.291s\n",
      "Bayesiano_TF('stop_words', 'norm_letters', 'pruning5')\n",
      "train time: 12.303s\n",
      "Bayesiano_TF('stemming', 'urls', 'norm_letters')\n",
      "train time: 12.734s\n",
      "Bayesiano_TF('stemming', 'urls', 'pruning10')\n",
      "train time: 12.840s\n",
      "Bayesiano_TF('stemming', 'urls', 'pruning5')\n",
      "train time: 12.993s\n",
      "Bayesiano_TF('stemming', 'norm_letters', 'pruning10')\n",
      "train time: 13.143s\n",
      "Bayesiano_TF('stemming', 'norm_letters', 'pruning5')\n",
      "train time: 13.627s\n",
      "Bayesiano_TF('lemmatization', 'urls', 'norm_letters')\n",
      "train time: 12.702s\n",
      "Bayesiano_TF('lemmatization', 'urls', 'pruning10')\n",
      "train time: 13.017s\n",
      "Bayesiano_TF('lemmatization', 'urls', 'pruning5')\n",
      "train time: 13.046s\n",
      "Bayesiano_TF('lemmatization', 'norm_letters', 'pruning10')\n",
      "train time: 13.757s\n",
      "Bayesiano_TF('lemmatization', 'norm_letters', 'pruning5')\n",
      "train time: 14.032s\n",
      "Bayesiano_TF('urls', 'norm_letters', 'pruning10')\n",
      "train time: 13.994s\n",
      "Bayesiano_TF('urls', 'norm_letters', 'pruning5')\n",
      "train time: 12.827s\n",
      "Bayesiano_TF('stop_words', 'stemming', 'urls', 'norm_letters')\n",
      "train time: 13.839s\n",
      "Bayesiano_TF('stop_words', 'stemming', 'urls', 'pruning10')\n",
      "train time: 14.334s\n",
      "Bayesiano_TF('stop_words', 'stemming', 'urls', 'pruning5')\n",
      "train time: 13.959s\n",
      "Bayesiano_TF('stop_words', 'stemming', 'norm_letters', 'pruning10')\n",
      "train time: 14.034s\n",
      "Bayesiano_TF('stop_words', 'stemming', 'norm_letters', 'pruning5')\n",
      "train time: 13.794s\n",
      "Bayesiano_TF('stop_words', 'lemmatization', 'urls', 'norm_letters')\n",
      "train time: 13.770s\n",
      "Bayesiano_TF('stop_words', 'lemmatization', 'urls', 'pruning10')\n",
      "train time: 14.873s\n",
      "Bayesiano_TF('stop_words', 'lemmatization', 'urls', 'pruning5')\n",
      "train time: 13.924s\n",
      "Bayesiano_TF('stop_words', 'lemmatization', 'norm_letters', 'pruning10')\n",
      "train time: 13.993s\n",
      "Bayesiano_TF('stop_words', 'lemmatization', 'norm_letters', 'pruning5')\n",
      "train time: 14.714s\n",
      "Bayesiano_TF('stop_words', 'urls', 'norm_letters', 'pruning10')\n",
      "train time: 15.040s\n",
      "Bayesiano_TF('stop_words', 'urls', 'norm_letters', 'pruning5')\n",
      "train time: 13.886s\n",
      "Bayesiano_TF('stemming', 'urls', 'norm_letters', 'pruning10')\n",
      "train time: 15.079s\n",
      "Bayesiano_TF('stemming', 'urls', 'norm_letters', 'pruning5')\n",
      "train time: 14.300s\n",
      "Bayesiano_TF('lemmatization', 'urls', 'norm_letters', 'pruning10')\n",
      "train time: 14.406s\n",
      "Bayesiano_TF('lemmatization', 'urls', 'norm_letters', 'pruning5')\n",
      "train time: 14.335s\n",
      "Bayesiano_TF('stop_words', 'stemming', 'urls', 'norm_letters', 'pruning10')\n",
      "train time: 14.816s\n",
      "Bayesiano_TF('stop_words', 'stemming', 'urls', 'norm_letters', 'pruning5')\n",
      "train time: 14.965s\n",
      "Bayesiano_TF('stop_words', 'lemmatization', 'urls', 'norm_letters', 'pruning10')\n",
      "train time: 15.379s\n",
      "Bayesiano_TF('stop_words', 'lemmatization', 'urls', 'norm_letters', 'pruning5')\n",
      "train time: 15.485s\n",
      "Bayesiano_TF-IDF('stop_words',)\n",
      "train time: 15.556s\n",
      "Bayesiano_TF-IDF('stemming',)\n",
      "train time: 16.007s\n",
      "Bayesiano_TF-IDF('lemmatization',)\n",
      "train time: 15.378s\n",
      "Bayesiano_TF-IDF('urls',)\n",
      "train time: 15.795s\n",
      "Bayesiano_TF-IDF('norm_letters',)\n",
      "train time: 16.173s\n",
      "Bayesiano_TF-IDF('pruning10',)\n",
      "train time: 16.138s\n",
      "Bayesiano_TF-IDF('pruning5',)\n",
      "train time: 16.056s\n",
      "Bayesiano_TF-IDF('stop_words', 'stemming')\n",
      "train time: 16.489s\n",
      "Bayesiano_TF-IDF('stop_words', 'lemmatization')\n",
      "train time: 16.558s\n",
      "Bayesiano_TF-IDF('stop_words', 'urls')\n",
      "train time: 16.337s\n",
      "Bayesiano_TF-IDF('stop_words', 'norm_letters')\n",
      "train time: 16.633s\n",
      "Bayesiano_TF-IDF('stop_words', 'pruning10')\n",
      "train time: 16.170s\n",
      "Bayesiano_TF-IDF('stop_words', 'pruning5')\n",
      "train time: 17.094s\n",
      "Bayesiano_TF-IDF('stemming', 'urls')\n",
      "train time: 16.280s\n",
      "Bayesiano_TF-IDF('stemming', 'norm_letters')\n",
      "train time: 16.915s\n",
      "Bayesiano_TF-IDF('stemming', 'pruning10')\n",
      "train time: 17.116s\n",
      "Bayesiano_TF-IDF('stemming', 'pruning5')\n",
      "train time: 17.125s\n",
      "Bayesiano_TF-IDF('lemmatization', 'urls')\n",
      "train time: 16.555s\n",
      "Bayesiano_TF-IDF('lemmatization', 'norm_letters')\n",
      "train time: 17.240s\n",
      "Bayesiano_TF-IDF('lemmatization', 'pruning10')\n",
      "train time: 17.788s\n",
      "Bayesiano_TF-IDF('lemmatization', 'pruning5')\n",
      "train time: 17.749s\n",
      "Bayesiano_TF-IDF('urls', 'norm_letters')\n",
      "train time: 17.728s\n",
      "Bayesiano_TF-IDF('urls', 'pruning10')\n",
      "train time: 17.272s\n",
      "Bayesiano_TF-IDF('urls', 'pruning5')\n",
      "train time: 17.629s\n",
      "Bayesiano_TF-IDF('norm_letters', 'pruning10')\n",
      "train time: 18.659s\n",
      "Bayesiano_TF-IDF('norm_letters', 'pruning5')\n",
      "train time: 18.346s\n",
      "Bayesiano_TF-IDF('stop_words', 'stemming', 'urls')\n",
      "train time: 17.646s\n",
      "Bayesiano_TF-IDF('stop_words', 'stemming', 'norm_letters')\n",
      "train time: 17.424s\n",
      "Bayesiano_TF-IDF('stop_words', 'stemming', 'pruning10')\n",
      "train time: 17.120s\n",
      "Bayesiano_TF-IDF('stop_words', 'stemming', 'pruning5')\n",
      "train time: 17.527s\n",
      "Bayesiano_TF-IDF('stop_words', 'lemmatization', 'urls')\n",
      "train time: 18.409s\n",
      "Bayesiano_TF-IDF('stop_words', 'lemmatization', 'norm_letters')\n",
      "train time: 18.283s\n",
      "Bayesiano_TF-IDF('stop_words', 'lemmatization', 'pruning10')\n",
      "train time: 17.724s\n",
      "Bayesiano_TF-IDF('stop_words', 'lemmatization', 'pruning5')\n",
      "train time: 18.065s\n",
      "Bayesiano_TF-IDF('stop_words', 'urls', 'norm_letters')\n",
      "train time: 18.618s\n",
      "Bayesiano_TF-IDF('stop_words', 'urls', 'pruning10')\n",
      "train time: 18.646s\n",
      "Bayesiano_TF-IDF('stop_words', 'urls', 'pruning5')\n",
      "train time: 18.842s\n",
      "Bayesiano_TF-IDF('stop_words', 'norm_letters', 'pruning10')\n",
      "train time: 19.350s\n",
      "Bayesiano_TF-IDF('stop_words', 'norm_letters', 'pruning5')\n",
      "train time: 19.441s\n",
      "Bayesiano_TF-IDF('stemming', 'urls', 'norm_letters')\n",
      "train time: 19.659s\n",
      "Bayesiano_TF-IDF('stemming', 'urls', 'pruning10')\n",
      "train time: 19.858s\n",
      "Bayesiano_TF-IDF('stemming', 'urls', 'pruning5')\n",
      "train time: 20.026s\n",
      "Bayesiano_TF-IDF('stemming', 'norm_letters', 'pruning10')\n",
      "train time: 20.040s\n",
      "Bayesiano_TF-IDF('stemming', 'norm_letters', 'pruning5')\n",
      "train time: 19.965s\n",
      "Bayesiano_TF-IDF('lemmatization', 'urls', 'norm_letters')\n",
      "train time: 19.334s\n",
      "Bayesiano_TF-IDF('lemmatization', 'urls', 'pruning10')\n",
      "train time: 20.468s\n",
      "Bayesiano_TF-IDF('lemmatization', 'urls', 'pruning5')\n",
      "train time: 19.013s\n",
      "Bayesiano_TF-IDF('lemmatization', 'norm_letters', 'pruning10')\n",
      "train time: 19.282s\n",
      "Bayesiano_TF-IDF('lemmatization', 'norm_letters', 'pruning5')\n",
      "train time: 20.215s\n",
      "Bayesiano_TF-IDF('urls', 'norm_letters', 'pruning10')\n",
      "train time: 21.248s\n",
      "Bayesiano_TF-IDF('urls', 'norm_letters', 'pruning5')\n",
      "train time: 20.795s\n",
      "Bayesiano_TF-IDF('stop_words', 'stemming', 'urls', 'norm_letters')\n",
      "train time: 20.503s\n",
      "Bayesiano_TF-IDF('stop_words', 'stemming', 'urls', 'pruning10')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 20.884s\n",
      "Bayesiano_TF-IDF('stop_words', 'stemming', 'urls', 'pruning5')\n",
      "train time: 20.143s\n",
      "Bayesiano_TF-IDF('stop_words', 'stemming', 'norm_letters', 'pruning10')\n",
      "train time: 19.966s\n",
      "Bayesiano_TF-IDF('stop_words', 'stemming', 'norm_letters', 'pruning5')\n",
      "train time: 19.750s\n",
      "Bayesiano_TF-IDF('stop_words', 'lemmatization', 'urls', 'norm_letters')\n",
      "train time: 21.121s\n",
      "Bayesiano_TF-IDF('stop_words', 'lemmatization', 'urls', 'pruning10')\n",
      "train time: 20.862s\n",
      "Bayesiano_TF-IDF('stop_words', 'lemmatization', 'urls', 'pruning5')\n",
      "train time: 21.118s\n",
      "Bayesiano_TF-IDF('stop_words', 'lemmatization', 'norm_letters', 'pruning10')\n",
      "train time: 20.863s\n",
      "Bayesiano_TF-IDF('stop_words', 'lemmatization', 'norm_letters', 'pruning5')\n",
      "train time: 21.965s\n",
      "Bayesiano_TF-IDF('stop_words', 'urls', 'norm_letters', 'pruning10')\n",
      "train time: 20.532s\n",
      "Bayesiano_TF-IDF('stop_words', 'urls', 'norm_letters', 'pruning5')\n",
      "train time: 21.388s\n",
      "Bayesiano_TF-IDF('stemming', 'urls', 'norm_letters', 'pruning10')\n",
      "train time: 21.156s\n",
      "Bayesiano_TF-IDF('stemming', 'urls', 'norm_letters', 'pruning5')\n",
      "train time: 21.002s\n",
      "Bayesiano_TF-IDF('lemmatization', 'urls', 'norm_letters', 'pruning10')\n",
      "train time: 21.811s\n",
      "Bayesiano_TF-IDF('lemmatization', 'urls', 'norm_letters', 'pruning5')\n",
      "train time: 20.852s\n",
      "Bayesiano_TF-IDF('stop_words', 'stemming', 'urls', 'norm_letters', 'pruning10')\n",
      "train time: 21.774s\n",
      "Bayesiano_TF-IDF('stop_words', 'stemming', 'urls', 'norm_letters', 'pruning5')\n",
      "train time: 21.066s\n",
      "Bayesiano_TF-IDF('stop_words', 'lemmatization', 'urls', 'norm_letters', 'pruning10')\n",
      "train time: 22.824s\n",
      "Bayesiano_TF-IDF('stop_words', 'lemmatization', 'urls', 'norm_letters', 'pruning5')\n",
      "train time: 21.556s\n",
      "Bayesiano_Binario('stop_words',)\n",
      "train time: 22.474s\n",
      "Bayesiano_Binario('stemming',)\n",
      "train time: 21.928s\n",
      "Bayesiano_Binario('lemmatization',)\n",
      "train time: 21.457s\n",
      "Bayesiano_Binario('urls',)\n",
      "train time: 22.333s\n",
      "Bayesiano_Binario('norm_letters',)\n",
      "train time: 22.681s\n",
      "Bayesiano_Binario('pruning10',)\n",
      "train time: 22.974s\n",
      "Bayesiano_Binario('pruning5',)\n",
      "train time: 23.044s\n",
      "Bayesiano_Binario('stop_words', 'stemming')\n",
      "train time: 22.998s\n",
      "Bayesiano_Binario('stop_words', 'lemmatization')\n",
      "train time: 22.393s\n",
      "Bayesiano_Binario('stop_words', 'urls')\n",
      "train time: 22.473s\n",
      "Bayesiano_Binario('stop_words', 'norm_letters')\n",
      "train time: 22.548s\n",
      "Bayesiano_Binario('stop_words', 'pruning10')\n",
      "train time: 23.642s\n",
      "Bayesiano_Binario('stop_words', 'pruning5')\n",
      "train time: 22.839s\n",
      "Bayesiano_Binario('stemming', 'urls')\n",
      "train time: 23.633s\n",
      "Bayesiano_Binario('stemming', 'norm_letters')\n",
      "train time: 22.776s\n",
      "Bayesiano_Binario('stemming', 'pruning10')\n",
      "train time: 24.483s\n",
      "Bayesiano_Binario('stemming', 'pruning5')\n",
      "train time: 24.418s\n",
      "Bayesiano_Binario('lemmatization', 'urls')\n",
      "train time: 24.480s\n",
      "Bayesiano_Binario('lemmatization', 'norm_letters')\n",
      "train time: 24.981s\n",
      "Bayesiano_Binario('lemmatization', 'pruning10')\n",
      "train time: 24.518s\n",
      "Bayesiano_Binario('lemmatization', 'pruning5')\n",
      "train time: 24.625s\n",
      "Bayesiano_Binario('urls', 'norm_letters')\n",
      "train time: 24.550s\n",
      "Bayesiano_Binario('urls', 'pruning10')\n",
      "train time: 23.143s\n",
      "Bayesiano_Binario('urls', 'pruning5')\n",
      "train time: 23.158s\n",
      "Bayesiano_Binario('norm_letters', 'pruning10')\n",
      "train time: 24.228s\n",
      "Bayesiano_Binario('norm_letters', 'pruning5')\n",
      "train time: 24.105s\n",
      "Bayesiano_Binario('stop_words', 'stemming', 'urls')\n",
      "train time: 25.454s\n",
      "Bayesiano_Binario('stop_words', 'stemming', 'norm_letters')\n",
      "train time: 25.852s\n",
      "Bayesiano_Binario('stop_words', 'stemming', 'pruning10')\n",
      "train time: 25.005s\n",
      "Bayesiano_Binario('stop_words', 'stemming', 'pruning5')\n",
      "train time: 24.769s\n",
      "Bayesiano_Binario('stop_words', 'lemmatization', 'urls')\n",
      "train time: 24.457s\n",
      "Bayesiano_Binario('stop_words', 'lemmatization', 'norm_letters')\n",
      "train time: 24.908s\n",
      "Bayesiano_Binario('stop_words', 'lemmatization', 'pruning10')\n",
      "train time: 24.214s\n",
      "Bayesiano_Binario('stop_words', 'lemmatization', 'pruning5')\n",
      "train time: 25.975s\n",
      "Bayesiano_Binario('stop_words', 'urls', 'norm_letters')\n",
      "train time: 26.206s\n",
      "Bayesiano_Binario('stop_words', 'urls', 'pruning10')\n",
      "train time: 26.250s\n",
      "Bayesiano_Binario('stop_words', 'urls', 'pruning5')\n",
      "train time: 24.549s\n",
      "Bayesiano_Binario('stop_words', 'norm_letters', 'pruning10')\n",
      "train time: 25.219s\n",
      "Bayesiano_Binario('stop_words', 'norm_letters', 'pruning5')\n",
      "train time: 26.333s\n",
      "Bayesiano_Binario('stemming', 'urls', 'norm_letters')\n",
      "train time: 25.025s\n",
      "Bayesiano_Binario('stemming', 'urls', 'pruning10')\n",
      "train time: 26.003s\n",
      "Bayesiano_Binario('stemming', 'urls', 'pruning5')\n",
      "train time: 25.924s\n",
      "Bayesiano_Binario('stemming', 'norm_letters', 'pruning10')\n",
      "train time: 25.856s\n",
      "Bayesiano_Binario('stemming', 'norm_letters', 'pruning5')\n",
      "train time: 26.492s\n",
      "Bayesiano_Binario('lemmatization', 'urls', 'norm_letters')\n",
      "train time: 26.300s\n",
      "Bayesiano_Binario('lemmatization', 'urls', 'pruning10')\n",
      "train time: 26.944s\n",
      "Bayesiano_Binario('lemmatization', 'urls', 'pruning5')\n",
      "train time: 26.383s\n",
      "Bayesiano_Binario('lemmatization', 'norm_letters', 'pruning10')\n",
      "train time: 25.968s\n",
      "Bayesiano_Binario('lemmatization', 'norm_letters', 'pruning5')\n",
      "train time: 26.902s\n",
      "Bayesiano_Binario('urls', 'norm_letters', 'pruning10')\n",
      "train time: 27.245s\n",
      "Bayesiano_Binario('urls', 'norm_letters', 'pruning5')\n",
      "train time: 27.182s\n",
      "Bayesiano_Binario('stop_words', 'stemming', 'urls', 'norm_letters')\n",
      "train time: 25.902s\n",
      "Bayesiano_Binario('stop_words', 'stemming', 'urls', 'pruning10')\n",
      "train time: 26.721s\n",
      "Bayesiano_Binario('stop_words', 'stemming', 'urls', 'pruning5')\n",
      "train time: 27.006s\n",
      "Bayesiano_Binario('stop_words', 'stemming', 'norm_letters', 'pruning10')\n",
      "train time: 27.871s\n",
      "Bayesiano_Binario('stop_words', 'stemming', 'norm_letters', 'pruning5')\n",
      "train time: 27.319s\n",
      "Bayesiano_Binario('stop_words', 'lemmatization', 'urls', 'norm_letters')\n",
      "train time: 27.596s\n",
      "Bayesiano_Binario('stop_words', 'lemmatization', 'urls', 'pruning10')\n",
      "train time: 27.661s\n",
      "Bayesiano_Binario('stop_words', 'lemmatization', 'urls', 'pruning5')\n",
      "train time: 27.870s\n",
      "Bayesiano_Binario('stop_words', 'lemmatization', 'norm_letters', 'pruning10')\n",
      "train time: 26.857s\n",
      "Bayesiano_Binario('stop_words', 'lemmatization', 'norm_letters', 'pruning5')\n",
      "train time: 27.158s\n",
      "Bayesiano_Binario('stop_words', 'urls', 'norm_letters', 'pruning10')\n",
      "train time: 27.877s\n",
      "Bayesiano_Binario('stop_words', 'urls', 'norm_letters', 'pruning5')\n",
      "train time: 28.283s\n",
      "Bayesiano_Binario('stemming', 'urls', 'norm_letters', 'pruning10')\n",
      "train time: 28.392s\n",
      "Bayesiano_Binario('stemming', 'urls', 'norm_letters', 'pruning5')\n",
      "train time: 28.189s\n",
      "Bayesiano_Binario('lemmatization', 'urls', 'norm_letters', 'pruning10')\n",
      "train time: 28.191s\n",
      "Bayesiano_Binario('lemmatization', 'urls', 'norm_letters', 'pruning5')\n",
      "train time: 28.457s\n",
      "Bayesiano_Binario('stop_words', 'stemming', 'urls', 'norm_letters', 'pruning10')\n",
      "train time: 27.437s\n",
      "Bayesiano_Binario('stop_words', 'stemming', 'urls', 'norm_letters', 'pruning5')\n",
      "train time: 27.160s\n",
      "Bayesiano_Binario('stop_words', 'lemmatization', 'urls', 'norm_letters', 'pruning10')\n",
      "train time: 27.582s\n",
      "Bayesiano_Binario('stop_words', 'lemmatization', 'urls', 'norm_letters', 'pruning5')\n",
      "train time: 27.936s\n",
      "SVM_lineal_TF('stop_words',)\n",
      "train time: 28.796s\n",
      "SVM_lineal_TF('stemming',)\n",
      "train time: 28.001s\n",
      "SVM_lineal_TF('lemmatization',)\n",
      "train time: 29.040s\n",
      "SVM_lineal_TF('urls',)\n",
      "train time: 29.975s\n",
      "SVM_lineal_TF('norm_letters',)\n",
      "train time: 30.203s\n",
      "SVM_lineal_TF('pruning10',)\n",
      "train time: 29.695s\n",
      "SVM_lineal_TF('pruning5',)\n",
      "train time: 29.513s\n",
      "SVM_lineal_TF('stop_words', 'stemming')\n",
      "train time: 29.132s\n",
      "SVM_lineal_TF('stop_words', 'lemmatization')\n",
      "train time: 29.106s\n",
      "SVM_lineal_TF('stop_words', 'urls')\n",
      "train time: 28.377s\n",
      "SVM_lineal_TF('stop_words', 'norm_letters')\n",
      "train time: 29.645s\n",
      "SVM_lineal_TF('stop_words', 'pruning10')\n",
      "train time: 29.748s\n",
      "SVM_lineal_TF('stop_words', 'pruning5')\n",
      "train time: 30.673s\n",
      "SVM_lineal_TF('stemming', 'urls')\n",
      "train time: 29.380s\n",
      "SVM_lineal_TF('stemming', 'norm_letters')\n",
      "train time: 30.950s\n",
      "SVM_lineal_TF('stemming', 'pruning10')\n",
      "train time: 31.161s\n",
      "SVM_lineal_TF('stemming', 'pruning5')\n",
      "train time: 29.439s\n",
      "SVM_lineal_TF('lemmatization', 'urls')\n",
      "train time: 29.977s\n",
      "SVM_lineal_TF('lemmatization', 'norm_letters')\n",
      "train time: 30.792s\n",
      "SVM_lineal_TF('lemmatization', 'pruning10')\n",
      "train time: 30.076s\n",
      "SVM_lineal_TF('lemmatization', 'pruning5')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 30.743s\n",
      "SVM_lineal_TF('urls', 'norm_letters')\n",
      "train time: 30.415s\n",
      "SVM_lineal_TF('urls', 'pruning10')\n",
      "train time: 29.312s\n",
      "SVM_lineal_TF('urls', 'pruning5')\n",
      "train time: 29.790s\n",
      "SVM_lineal_TF('norm_letters', 'pruning10')\n",
      "train time: 31.789s\n",
      "SVM_lineal_TF('norm_letters', 'pruning5')\n",
      "train time: 31.625s\n",
      "SVM_lineal_TF('stop_words', 'stemming', 'urls')\n",
      "train time: 30.761s\n",
      "SVM_lineal_TF('stop_words', 'stemming', 'norm_letters')\n",
      "train time: 30.692s\n",
      "SVM_lineal_TF('stop_words', 'stemming', 'pruning10')\n",
      "train time: 32.271s\n",
      "SVM_lineal_TF('stop_words', 'stemming', 'pruning5')\n",
      "train time: 31.541s\n",
      "SVM_lineal_TF('stop_words', 'lemmatization', 'urls')\n",
      "train time: 30.278s\n",
      "SVM_lineal_TF('stop_words', 'lemmatization', 'norm_letters')\n",
      "train time: 31.083s\n",
      "SVM_lineal_TF('stop_words', 'lemmatization', 'pruning10')\n",
      "train time: 31.731s\n",
      "SVM_lineal_TF('stop_words', 'lemmatization', 'pruning5')\n",
      "train time: 31.051s\n",
      "SVM_lineal_TF('stop_words', 'urls', 'norm_letters')\n",
      "train time: 31.573s\n",
      "SVM_lineal_TF('stop_words', 'urls', 'pruning10')\n",
      "train time: 31.754s\n",
      "SVM_lineal_TF('stop_words', 'urls', 'pruning5')\n",
      "train time: 31.831s\n",
      "SVM_lineal_TF('stop_words', 'norm_letters', 'pruning10')\n",
      "train time: 31.031s\n",
      "SVM_lineal_TF('stop_words', 'norm_letters', 'pruning5')\n",
      "train time: 32.186s\n",
      "SVM_lineal_TF('stemming', 'urls', 'norm_letters')\n",
      "train time: 31.546s\n",
      "SVM_lineal_TF('stemming', 'urls', 'pruning10')\n",
      "train time: 32.817s\n",
      "SVM_lineal_TF('stemming', 'urls', 'pruning5')\n",
      "train time: 31.557s\n",
      "SVM_lineal_TF('stemming', 'norm_letters', 'pruning10')\n",
      "train time: 33.373s\n",
      "SVM_lineal_TF('stemming', 'norm_letters', 'pruning5')\n",
      "train time: 32.604s\n",
      "SVM_lineal_TF('lemmatization', 'urls', 'norm_letters')\n",
      "train time: 31.401s\n",
      "SVM_lineal_TF('lemmatization', 'urls', 'pruning10')\n",
      "train time: 31.463s\n",
      "SVM_lineal_TF('lemmatization', 'urls', 'pruning5')\n",
      "train time: 33.175s\n",
      "SVM_lineal_TF('lemmatization', 'norm_letters', 'pruning10')\n",
      "train time: 32.214s\n",
      "SVM_lineal_TF('lemmatization', 'norm_letters', 'pruning5')\n",
      "train time: 32.091s\n",
      "SVM_lineal_TF('urls', 'norm_letters', 'pruning10')\n",
      "train time: 34.197s\n",
      "SVM_lineal_TF('urls', 'norm_letters', 'pruning5')\n",
      "train time: 34.540s\n",
      "SVM_lineal_TF('stop_words', 'stemming', 'urls', 'norm_letters')\n",
      "train time: 33.373s\n",
      "SVM_lineal_TF('stop_words', 'stemming', 'urls', 'pruning10')\n",
      "train time: 34.230s\n",
      "SVM_lineal_TF('stop_words', 'stemming', 'urls', 'pruning5')\n",
      "train time: 33.928s\n",
      "SVM_lineal_TF('stop_words', 'stemming', 'norm_letters', 'pruning10')\n",
      "train time: 32.521s\n",
      "SVM_lineal_TF('stop_words', 'stemming', 'norm_letters', 'pruning5')\n",
      "train time: 34.259s\n",
      "SVM_lineal_TF('stop_words', 'lemmatization', 'urls', 'norm_letters')\n",
      "train time: 33.098s\n",
      "SVM_lineal_TF('stop_words', 'lemmatization', 'urls', 'pruning10')\n",
      "train time: 33.259s\n",
      "SVM_lineal_TF('stop_words', 'lemmatization', 'urls', 'pruning5')\n",
      "train time: 32.767s\n",
      "SVM_lineal_TF('stop_words', 'lemmatization', 'norm_letters', 'pruning10')\n",
      "train time: 34.945s\n",
      "SVM_lineal_TF('stop_words', 'lemmatization', 'norm_letters', 'pruning5')\n",
      "train time: 33.398s\n",
      "SVM_lineal_TF('stop_words', 'urls', 'norm_letters', 'pruning10')\n",
      "train time: 33.015s\n",
      "SVM_lineal_TF('stop_words', 'urls', 'norm_letters', 'pruning5')\n",
      "train time: 34.826s\n",
      "SVM_lineal_TF('stemming', 'urls', 'norm_letters', 'pruning10')\n",
      "train time: 34.062s\n",
      "SVM_lineal_TF('stemming', 'urls', 'norm_letters', 'pruning5')\n",
      "train time: 33.866s\n",
      "SVM_lineal_TF('lemmatization', 'urls', 'norm_letters', 'pruning10')\n",
      "train time: 34.049s\n",
      "SVM_lineal_TF('lemmatization', 'urls', 'norm_letters', 'pruning5')\n",
      "train time: 34.807s\n",
      "SVM_lineal_TF('stop_words', 'stemming', 'urls', 'norm_letters', 'pruning10')\n",
      "train time: 35.175s\n",
      "SVM_lineal_TF('stop_words', 'stemming', 'urls', 'norm_letters', 'pruning5')\n",
      "train time: 36.223s\n",
      "SVM_lineal_TF('stop_words', 'lemmatization', 'urls', 'norm_letters', 'pruning10')\n",
      "train time: 33.476s\n",
      "SVM_lineal_TF('stop_words', 'lemmatization', 'urls', 'norm_letters', 'pruning5')\n",
      "train time: 35.720s\n",
      "SVM_lineal_TF-IDF('stop_words',)\n",
      "train time: 33.728s\n",
      "SVM_lineal_TF-IDF('stemming',)\n",
      "train time: 36.216s\n",
      "SVM_lineal_TF-IDF('lemmatization',)\n",
      "train time: 33.955s\n",
      "SVM_lineal_TF-IDF('urls',)\n",
      "train time: 35.624s\n",
      "SVM_lineal_TF-IDF('norm_letters',)\n",
      "train time: 34.651s\n",
      "SVM_lineal_TF-IDF('pruning10',)\n",
      "train time: 36.099s\n",
      "SVM_lineal_TF-IDF('pruning5',)\n",
      "train time: 36.212s\n",
      "SVM_lineal_TF-IDF('stop_words', 'stemming')\n",
      "train time: 35.402s\n",
      "SVM_lineal_TF-IDF('stop_words', 'lemmatization')\n",
      "train time: 36.566s\n",
      "SVM_lineal_TF-IDF('stop_words', 'urls')\n",
      "train time: 36.974s\n",
      "SVM_lineal_TF-IDF('stop_words', 'norm_letters')\n",
      "train time: 34.409s\n",
      "SVM_lineal_TF-IDF('stop_words', 'pruning10')\n",
      "train time: 34.699s\n",
      "SVM_lineal_TF-IDF('stop_words', 'pruning5')\n",
      "train time: 36.171s\n",
      "SVM_lineal_TF-IDF('stemming', 'urls')\n",
      "train time: 36.407s\n",
      "SVM_lineal_TF-IDF('stemming', 'norm_letters')\n",
      "train time: 35.697s\n",
      "SVM_lineal_TF-IDF('stemming', 'pruning10')\n",
      "train time: 36.579s\n",
      "SVM_lineal_TF-IDF('stemming', 'pruning5')\n",
      "train time: 36.418s\n",
      "SVM_lineal_TF-IDF('lemmatization', 'urls')\n",
      "train time: 37.900s\n",
      "SVM_lineal_TF-IDF('lemmatization', 'norm_letters')\n",
      "train time: 37.207s\n",
      "SVM_lineal_TF-IDF('lemmatization', 'pruning10')\n",
      "train time: 37.162s\n",
      "SVM_lineal_TF-IDF('lemmatization', 'pruning5')\n",
      "train time: 36.737s\n",
      "SVM_lineal_TF-IDF('urls', 'norm_letters')\n",
      "train time: 36.279s\n",
      "SVM_lineal_TF-IDF('urls', 'pruning10')\n",
      "train time: 37.173s\n",
      "SVM_lineal_TF-IDF('urls', 'pruning5')\n",
      "train time: 37.894s\n",
      "SVM_lineal_TF-IDF('norm_letters', 'pruning10')\n",
      "train time: 36.159s\n",
      "SVM_lineal_TF-IDF('norm_letters', 'pruning5')\n",
      "train time: 37.711s\n",
      "SVM_lineal_TF-IDF('stop_words', 'stemming', 'urls')\n",
      "train time: 38.364s\n",
      "SVM_lineal_TF-IDF('stop_words', 'stemming', 'norm_letters')\n",
      "train time: 37.211s\n",
      "SVM_lineal_TF-IDF('stop_words', 'stemming', 'pruning10')\n",
      "train time: 38.185s\n",
      "SVM_lineal_TF-IDF('stop_words', 'stemming', 'pruning5')\n",
      "train time: 37.419s\n",
      "SVM_lineal_TF-IDF('stop_words', 'lemmatization', 'urls')\n",
      "train time: 38.692s\n",
      "SVM_lineal_TF-IDF('stop_words', 'lemmatization', 'norm_letters')\n",
      "train time: 38.976s\n",
      "SVM_lineal_TF-IDF('stop_words', 'lemmatization', 'pruning10')\n",
      "train time: 37.582s\n",
      "SVM_lineal_TF-IDF('stop_words', 'lemmatization', 'pruning5')\n",
      "train time: 37.867s\n",
      "SVM_lineal_TF-IDF('stop_words', 'urls', 'norm_letters')\n",
      "train time: 39.429s\n",
      "SVM_lineal_TF-IDF('stop_words', 'urls', 'pruning10')\n",
      "train time: 37.155s\n",
      "SVM_lineal_TF-IDF('stop_words', 'urls', 'pruning5')\n",
      "train time: 39.360s\n",
      "SVM_lineal_TF-IDF('stop_words', 'norm_letters', 'pruning10')\n",
      "train time: 39.334s\n",
      "SVM_lineal_TF-IDF('stop_words', 'norm_letters', 'pruning5')\n",
      "train time: 38.086s\n",
      "SVM_lineal_TF-IDF('stemming', 'urls', 'norm_letters')\n",
      "train time: 38.003s\n",
      "SVM_lineal_TF-IDF('stemming', 'urls', 'pruning10')\n",
      "train time: 38.737s\n",
      "SVM_lineal_TF-IDF('stemming', 'urls', 'pruning5')\n",
      "train time: 38.920s\n",
      "SVM_lineal_TF-IDF('stemming', 'norm_letters', 'pruning10')\n",
      "train time: 38.819s\n",
      "SVM_lineal_TF-IDF('stemming', 'norm_letters', 'pruning5')\n",
      "train time: 39.715s\n",
      "SVM_lineal_TF-IDF('lemmatization', 'urls', 'norm_letters')\n",
      "train time: 39.024s\n",
      "SVM_lineal_TF-IDF('lemmatization', 'urls', 'pruning10')\n",
      "train time: 39.202s\n",
      "SVM_lineal_TF-IDF('lemmatization', 'urls', 'pruning5')\n",
      "train time: 39.332s\n",
      "SVM_lineal_TF-IDF('lemmatization', 'norm_letters', 'pruning10')\n",
      "train time: 39.883s\n",
      "SVM_lineal_TF-IDF('lemmatization', 'norm_letters', 'pruning5')\n",
      "train time: 38.797s\n",
      "SVM_lineal_TF-IDF('urls', 'norm_letters', 'pruning10')\n",
      "train time: 38.395s\n",
      "SVM_lineal_TF-IDF('urls', 'norm_letters', 'pruning5')\n",
      "train time: 39.859s\n",
      "SVM_lineal_TF-IDF('stop_words', 'stemming', 'urls', 'norm_letters')\n",
      "train time: 40.721s\n",
      "SVM_lineal_TF-IDF('stop_words', 'stemming', 'urls', 'pruning10')\n",
      "train time: 40.739s\n",
      "SVM_lineal_TF-IDF('stop_words', 'stemming', 'urls', 'pruning5')\n",
      "train time: 41.025s\n",
      "SVM_lineal_TF-IDF('stop_words', 'stemming', 'norm_letters', 'pruning10')\n",
      "train time: 41.117s\n",
      "SVM_lineal_TF-IDF('stop_words', 'stemming', 'norm_letters', 'pruning5')\n",
      "train time: 38.247s\n",
      "SVM_lineal_TF-IDF('stop_words', 'lemmatization', 'urls', 'norm_letters')\n",
      "train time: 39.393s\n",
      "SVM_lineal_TF-IDF('stop_words', 'lemmatization', 'urls', 'pruning10')\n",
      "train time: 41.214s\n",
      "SVM_lineal_TF-IDF('stop_words', 'lemmatization', 'urls', 'pruning5')\n",
      "train time: 41.059s\n",
      "SVM_lineal_TF-IDF('stop_words', 'lemmatization', 'norm_letters', 'pruning10')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 39.937s\n",
      "SVM_lineal_TF-IDF('stop_words', 'lemmatization', 'norm_letters', 'pruning5')\n",
      "train time: 41.045s\n",
      "SVM_lineal_TF-IDF('stop_words', 'urls', 'norm_letters', 'pruning10')\n",
      "train time: 41.506s\n",
      "SVM_lineal_TF-IDF('stop_words', 'urls', 'norm_letters', 'pruning5')\n",
      "train time: 41.816s\n",
      "SVM_lineal_TF-IDF('stemming', 'urls', 'norm_letters', 'pruning10')\n",
      "train time: 42.067s\n",
      "SVM_lineal_TF-IDF('stemming', 'urls', 'norm_letters', 'pruning5')\n",
      "train time: 41.990s\n",
      "SVM_lineal_TF-IDF('lemmatization', 'urls', 'norm_letters', 'pruning10')\n",
      "train time: 42.119s\n",
      "SVM_lineal_TF-IDF('lemmatization', 'urls', 'norm_letters', 'pruning5')\n",
      "train time: 40.614s\n",
      "SVM_lineal_TF-IDF('stop_words', 'stemming', 'urls', 'norm_letters', 'pruning10')\n",
      "train time: 40.146s\n",
      "SVM_lineal_TF-IDF('stop_words', 'stemming', 'urls', 'norm_letters', 'pruning5')\n",
      "train time: 42.016s\n",
      "SVM_lineal_TF-IDF('stop_words', 'lemmatization', 'urls', 'norm_letters', 'pruning10')\n",
      "train time: 43.065s\n",
      "SVM_lineal_TF-IDF('stop_words', 'lemmatization', 'urls', 'norm_letters', 'pruning5')\n",
      "train time: 42.190s\n",
      "SVM_lineal_Binario('stop_words',)\n",
      "train time: 42.041s\n",
      "SVM_lineal_Binario('stemming',)\n",
      "train time: 41.591s\n",
      "SVM_lineal_Binario('lemmatization',)\n",
      "train time: 43.286s\n",
      "SVM_lineal_Binario('urls',)\n",
      "train time: 40.630s\n",
      "SVM_lineal_Binario('norm_letters',)\n",
      "train time: 40.418s\n",
      "SVM_lineal_Binario('pruning10',)\n",
      "train time: 42.092s\n",
      "SVM_lineal_Binario('pruning5',)\n",
      "train time: 41.370s\n",
      "SVM_lineal_Binario('stop_words', 'stemming')\n",
      "train time: 41.982s\n",
      "SVM_lineal_Binario('stop_words', 'lemmatization')\n",
      "train time: 43.932s\n",
      "SVM_lineal_Binario('stop_words', 'urls')\n",
      "train time: 43.031s\n",
      "SVM_lineal_Binario('stop_words', 'norm_letters')\n",
      "train time: 43.784s\n",
      "SVM_lineal_Binario('stop_words', 'pruning10')\n",
      "train time: 40.932s\n",
      "SVM_lineal_Binario('stop_words', 'pruning5')\n",
      "train time: 42.961s\n",
      "SVM_lineal_Binario('stemming', 'urls')\n",
      "train time: 43.269s\n",
      "SVM_lineal_Binario('stemming', 'norm_letters')\n",
      "train time: 43.894s\n",
      "SVM_lineal_Binario('stemming', 'pruning10')\n",
      "train time: 41.615s\n",
      "SVM_lineal_Binario('stemming', 'pruning5')\n",
      "train time: 43.943s\n",
      "SVM_lineal_Binario('lemmatization', 'urls')\n",
      "train time: 43.059s\n",
      "SVM_lineal_Binario('lemmatization', 'norm_letters')\n",
      "train time: 41.794s\n",
      "SVM_lineal_Binario('lemmatization', 'pruning10')\n",
      "train time: 43.252s\n",
      "SVM_lineal_Binario('lemmatization', 'pruning5')\n",
      "train time: 43.584s\n",
      "SVM_lineal_Binario('urls', 'norm_letters')\n",
      "train time: 44.021s\n",
      "SVM_lineal_Binario('urls', 'pruning10')\n",
      "train time: 43.716s\n",
      "SVM_lineal_Binario('urls', 'pruning5')\n",
      "train time: 44.294s\n",
      "SVM_lineal_Binario('norm_letters', 'pruning10')\n",
      "train time: 44.409s\n",
      "SVM_lineal_Binario('norm_letters', 'pruning5')\n",
      "train time: 44.385s\n",
      "SVM_lineal_Binario('stop_words', 'stemming', 'urls')\n",
      "train time: 44.782s\n",
      "SVM_lineal_Binario('stop_words', 'stemming', 'norm_letters')\n",
      "train time: 43.031s\n",
      "SVM_lineal_Binario('stop_words', 'stemming', 'pruning10')\n",
      "train time: 43.400s\n",
      "SVM_lineal_Binario('stop_words', 'stemming', 'pruning5')\n",
      "train time: 44.918s\n",
      "SVM_lineal_Binario('stop_words', 'lemmatization', 'urls')\n",
      "train time: 43.168s\n",
      "SVM_lineal_Binario('stop_words', 'lemmatization', 'norm_letters')\n",
      "train time: 44.108s\n",
      "SVM_lineal_Binario('stop_words', 'lemmatization', 'pruning10')\n",
      "train time: 43.321s\n",
      "SVM_lineal_Binario('stop_words', 'lemmatization', 'pruning5')\n",
      "train time: 44.880s\n",
      "SVM_lineal_Binario('stop_words', 'urls', 'norm_letters')\n",
      "train time: 44.879s\n",
      "SVM_lineal_Binario('stop_words', 'urls', 'pruning10')\n",
      "train time: 43.380s\n",
      "SVM_lineal_Binario('stop_words', 'urls', 'pruning5')\n",
      "train time: 46.275s\n",
      "SVM_lineal_Binario('stop_words', 'norm_letters', 'pruning10')\n",
      "train time: 45.945s\n",
      "SVM_lineal_Binario('stop_words', 'norm_letters', 'pruning5')\n",
      "train time: 45.871s\n",
      "SVM_lineal_Binario('stemming', 'urls', 'norm_letters')\n",
      "train time: 46.282s\n",
      "SVM_lineal_Binario('stemming', 'urls', 'pruning10')\n",
      "train time: 47.274s\n",
      "SVM_lineal_Binario('stemming', 'urls', 'pruning5')\n",
      "train time: 46.287s\n",
      "SVM_lineal_Binario('stemming', 'norm_letters', 'pruning10')\n",
      "train time: 45.715s\n",
      "SVM_lineal_Binario('stemming', 'norm_letters', 'pruning5')\n",
      "train time: 47.265s\n",
      "SVM_lineal_Binario('lemmatization', 'urls', 'norm_letters')\n",
      "train time: 46.527s\n",
      "SVM_lineal_Binario('lemmatization', 'urls', 'pruning10')\n",
      "train time: 47.663s\n",
      "SVM_lineal_Binario('lemmatization', 'urls', 'pruning5')\n",
      "train time: 45.373s\n",
      "SVM_lineal_Binario('lemmatization', 'norm_letters', 'pruning10')\n",
      "train time: 46.642s\n",
      "SVM_lineal_Binario('lemmatization', 'norm_letters', 'pruning5')\n",
      "train time: 47.042s\n",
      "SVM_lineal_Binario('urls', 'norm_letters', 'pruning10')\n",
      "train time: 44.596s\n",
      "SVM_lineal_Binario('urls', 'norm_letters', 'pruning5')\n",
      "train time: 46.251s\n",
      "SVM_lineal_Binario('stop_words', 'stemming', 'urls', 'norm_letters')\n",
      "train time: 47.330s\n",
      "SVM_lineal_Binario('stop_words', 'stemming', 'urls', 'pruning10')\n",
      "train time: 45.125s\n",
      "SVM_lineal_Binario('stop_words', 'stemming', 'urls', 'pruning5')\n",
      "train time: 46.654s\n",
      "SVM_lineal_Binario('stop_words', 'stemming', 'norm_letters', 'pruning10')\n",
      "train time: 46.235s\n",
      "SVM_lineal_Binario('stop_words', 'stemming', 'norm_letters', 'pruning5')\n",
      "train time: 46.395s\n",
      "SVM_lineal_Binario('stop_words', 'lemmatization', 'urls', 'norm_letters')\n",
      "train time: 47.567s\n",
      "SVM_lineal_Binario('stop_words', 'lemmatization', 'urls', 'pruning10')\n",
      "train time: 46.210s\n",
      "SVM_lineal_Binario('stop_words', 'lemmatization', 'urls', 'pruning5')\n",
      "train time: 44.824s\n",
      "SVM_lineal_Binario('stop_words', 'lemmatization', 'norm_letters', 'pruning10')\n",
      "train time: 48.621s\n",
      "SVM_lineal_Binario('stop_words', 'lemmatization', 'norm_letters', 'pruning5')\n",
      "train time: 47.298s\n",
      "SVM_lineal_Binario('stop_words', 'urls', 'norm_letters', 'pruning10')\n",
      "train time: 45.236s\n",
      "SVM_lineal_Binario('stop_words', 'urls', 'norm_letters', 'pruning5')\n",
      "train time: 48.103s\n",
      "SVM_lineal_Binario('stemming', 'urls', 'norm_letters', 'pruning10')\n",
      "train time: 49.068s\n",
      "SVM_lineal_Binario('stemming', 'urls', 'norm_letters', 'pruning5')\n",
      "train time: 49.233s\n",
      "SVM_lineal_Binario('lemmatization', 'urls', 'norm_letters', 'pruning10')\n",
      "train time: 47.401s\n",
      "SVM_lineal_Binario('lemmatization', 'urls', 'norm_letters', 'pruning5')\n",
      "train time: 49.362s\n",
      "SVM_lineal_Binario('stop_words', 'stemming', 'urls', 'norm_letters', 'pruning10')\n",
      "train time: 46.596s\n",
      "SVM_lineal_Binario('stop_words', 'stemming', 'urls', 'norm_letters', 'pruning5')\n",
      "train time: 48.866s\n",
      "SVM_lineal_Binario('stop_words', 'lemmatization', 'urls', 'norm_letters', 'pruning10')\n",
      "train time: 47.165s\n",
      "SVM_lineal_Binario('stop_words', 'lemmatization', 'urls', 'norm_letters', 'pruning5')\n",
      "train time: 48.088s\n",
      "Reg_Log_TF('stop_words',)\n",
      "train time: 47.183s\n",
      "Reg_Log_TF('stemming',)\n",
      "train time: 50.119s\n",
      "Reg_Log_TF('lemmatization',)\n",
      "train time: 49.805s\n",
      "Reg_Log_TF('urls',)\n",
      "train time: 50.090s\n",
      "Reg_Log_TF('norm_letters',)\n",
      "train time: 48.943s\n",
      "Reg_Log_TF('pruning10',)\n",
      "train time: 50.416s\n",
      "Reg_Log_TF('pruning5',)\n",
      "train time: 48.702s\n",
      "Reg_Log_TF('stop_words', 'stemming')\n",
      "train time: 47.775s\n",
      "Reg_Log_TF('stop_words', 'lemmatization')\n",
      "train time: 47.568s\n",
      "Reg_Log_TF('stop_words', 'urls')\n",
      "train time: 54.446s\n",
      "Reg_Log_TF('stop_words', 'norm_letters')\n",
      "train time: 48.416s\n",
      "Reg_Log_TF('stop_words', 'pruning10')\n",
      "train time: 49.193s\n",
      "Reg_Log_TF('stop_words', 'pruning5')\n",
      "train time: 48.888s\n",
      "Reg_Log_TF('stemming', 'urls')\n",
      "train time: 48.976s\n",
      "Reg_Log_TF('stemming', 'norm_letters')\n",
      "train time: 49.473s\n",
      "Reg_Log_TF('stemming', 'pruning10')\n",
      "train time: 50.379s\n",
      "Reg_Log_TF('stemming', 'pruning5')\n",
      "train time: 49.579s\n",
      "Reg_Log_TF('lemmatization', 'urls')\n",
      "train time: 48.955s\n",
      "Reg_Log_TF('lemmatization', 'norm_letters')\n",
      "train time: 49.509s\n",
      "Reg_Log_TF('lemmatization', 'pruning10')\n",
      "train time: 49.881s\n",
      "Reg_Log_TF('lemmatization', 'pruning5')\n",
      "train time: 50.101s\n",
      "Reg_Log_TF('urls', 'norm_letters')\n",
      "train time: 51.423s\n",
      "Reg_Log_TF('urls', 'pruning10')\n",
      "train time: 50.634s\n",
      "Reg_Log_TF('urls', 'pruning5')\n",
      "train time: 49.788s\n",
      "Reg_Log_TF('norm_letters', 'pruning10')\n",
      "train time: 51.340s\n",
      "Reg_Log_TF('norm_letters', 'pruning5')\n",
      "train time: 51.392s\n",
      "Reg_Log_TF('stop_words', 'stemming', 'urls')\n",
      "train time: 50.559s\n",
      "Reg_Log_TF('stop_words', 'stemming', 'norm_letters')\n",
      "train time: 50.799s\n",
      "Reg_Log_TF('stop_words', 'stemming', 'pruning10')\n",
      "train time: 50.201s\n",
      "Reg_Log_TF('stop_words', 'stemming', 'pruning5')\n",
      "train time: 50.007s\n",
      "Reg_Log_TF('stop_words', 'lemmatization', 'urls')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 51.279s\n",
      "Reg_Log_TF('stop_words', 'lemmatization', 'norm_letters')\n",
      "train time: 50.434s\n",
      "Reg_Log_TF('stop_words', 'lemmatization', 'pruning10')\n",
      "train time: 51.912s\n",
      "Reg_Log_TF('stop_words', 'lemmatization', 'pruning5')\n",
      "train time: 50.615s\n",
      "Reg_Log_TF('stop_words', 'urls', 'norm_letters')\n",
      "train time: 52.344s\n",
      "Reg_Log_TF('stop_words', 'urls', 'pruning10')\n",
      "train time: 50.424s\n",
      "Reg_Log_TF('stop_words', 'urls', 'pruning5')\n",
      "train time: 51.136s\n",
      "Reg_Log_TF('stop_words', 'norm_letters', 'pruning10')\n",
      "train time: 52.185s\n",
      "Reg_Log_TF('stop_words', 'norm_letters', 'pruning5')\n",
      "train time: 52.479s\n",
      "Reg_Log_TF('stemming', 'urls', 'norm_letters')\n",
      "train time: 51.878s\n",
      "Reg_Log_TF('stemming', 'urls', 'pruning10')\n",
      "train time: 51.545s\n",
      "Reg_Log_TF('stemming', 'urls', 'pruning5')\n",
      "train time: 53.329s\n",
      "Reg_Log_TF('stemming', 'norm_letters', 'pruning10')\n",
      "train time: 53.134s\n",
      "Reg_Log_TF('stemming', 'norm_letters', 'pruning5')\n",
      "train time: 51.813s\n",
      "Reg_Log_TF('lemmatization', 'urls', 'norm_letters')\n",
      "train time: 52.665s\n",
      "Reg_Log_TF('lemmatization', 'urls', 'pruning10')\n",
      "train time: 53.878s\n",
      "Reg_Log_TF('lemmatization', 'urls', 'pruning5')\n",
      "train time: 51.996s\n",
      "Reg_Log_TF('lemmatization', 'norm_letters', 'pruning10')\n",
      "train time: 53.731s\n",
      "Reg_Log_TF('lemmatization', 'norm_letters', 'pruning5')\n",
      "train time: 52.858s\n",
      "Reg_Log_TF('urls', 'norm_letters', 'pruning10')\n",
      "train time: 52.754s\n",
      "Reg_Log_TF('urls', 'norm_letters', 'pruning5')\n",
      "train time: 52.706s\n",
      "Reg_Log_TF('stop_words', 'stemming', 'urls', 'norm_letters')\n",
      "train time: 53.168s\n",
      "Reg_Log_TF('stop_words', 'stemming', 'urls', 'pruning10')\n",
      "train time: 52.398s\n",
      "Reg_Log_TF('stop_words', 'stemming', 'urls', 'pruning5')\n",
      "train time: 53.661s\n",
      "Reg_Log_TF('stop_words', 'stemming', 'norm_letters', 'pruning10')\n",
      "train time: 52.270s\n",
      "Reg_Log_TF('stop_words', 'stemming', 'norm_letters', 'pruning5')\n",
      "train time: 52.982s\n",
      "Reg_Log_TF('stop_words', 'lemmatization', 'urls', 'norm_letters')\n",
      "train time: 53.901s\n",
      "Reg_Log_TF('stop_words', 'lemmatization', 'urls', 'pruning10')\n",
      "train time: 52.704s\n",
      "Reg_Log_TF('stop_words', 'lemmatization', 'urls', 'pruning5')\n",
      "train time: 52.729s\n",
      "Reg_Log_TF('stop_words', 'lemmatization', 'norm_letters', 'pruning10')\n",
      "train time: 54.639s\n",
      "Reg_Log_TF('stop_words', 'lemmatization', 'norm_letters', 'pruning5')\n",
      "train time: 54.940s\n",
      "Reg_Log_TF('stop_words', 'urls', 'norm_letters', 'pruning10')\n",
      "train time: 54.595s\n",
      "Reg_Log_TF('stop_words', 'urls', 'norm_letters', 'pruning5')\n",
      "train time: 54.739s\n",
      "Reg_Log_TF('stemming', 'urls', 'norm_letters', 'pruning10')\n",
      "train time: 53.651s\n",
      "Reg_Log_TF('stemming', 'urls', 'norm_letters', 'pruning5')\n",
      "train time: 54.245s\n",
      "Reg_Log_TF('lemmatization', 'urls', 'norm_letters', 'pruning10')\n",
      "train time: 54.190s\n",
      "Reg_Log_TF('lemmatization', 'urls', 'norm_letters', 'pruning5')\n",
      "train time: 55.978s\n",
      "Reg_Log_TF('stop_words', 'stemming', 'urls', 'norm_letters', 'pruning10')\n",
      "train time: 55.332s\n",
      "Reg_Log_TF('stop_words', 'stemming', 'urls', 'norm_letters', 'pruning5')\n",
      "train time: 54.037s\n",
      "Reg_Log_TF('stop_words', 'lemmatization', 'urls', 'norm_letters', 'pruning10')\n",
      "train time: 53.877s\n",
      "Reg_Log_TF('stop_words', 'lemmatization', 'urls', 'norm_letters', 'pruning5')\n",
      "train time: 53.997s\n",
      "Reg_Log_TF-IDF('stop_words',)\n",
      "train time: 55.900s\n",
      "Reg_Log_TF-IDF('stemming',)\n",
      "train time: 56.248s\n",
      "Reg_Log_TF-IDF('lemmatization',)\n",
      "train time: 56.294s\n",
      "Reg_Log_TF-IDF('urls',)\n",
      "train time: 55.913s\n",
      "Reg_Log_TF-IDF('norm_letters',)\n",
      "train time: 56.119s\n",
      "Reg_Log_TF-IDF('pruning10',)\n",
      "train time: 54.466s\n",
      "Reg_Log_TF-IDF('pruning5',)\n",
      "train time: 55.482s\n",
      "Reg_Log_TF-IDF('stop_words', 'stemming')\n",
      "train time: 56.420s\n",
      "Reg_Log_TF-IDF('stop_words', 'lemmatization')\n",
      "train time: 54.908s\n",
      "Reg_Log_TF-IDF('stop_words', 'urls')\n",
      "train time: 55.641s\n",
      "Reg_Log_TF-IDF('stop_words', 'norm_letters')\n",
      "train time: 56.627s\n",
      "Reg_Log_TF-IDF('stop_words', 'pruning10')\n",
      "train time: 57.135s\n",
      "Reg_Log_TF-IDF('stop_words', 'pruning5')\n",
      "train time: 56.938s\n",
      "Reg_Log_TF-IDF('stemming', 'urls')\n",
      "train time: 55.715s\n",
      "Reg_Log_TF-IDF('stemming', 'norm_letters')\n",
      "train time: 57.427s\n",
      "Reg_Log_TF-IDF('stemming', 'pruning10')\n",
      "train time: 57.116s\n",
      "Reg_Log_TF-IDF('stemming', 'pruning5')\n",
      "train time: 55.714s\n",
      "Reg_Log_TF-IDF('lemmatization', 'urls')\n",
      "train time: 56.552s\n",
      "Reg_Log_TF-IDF('lemmatization', 'norm_letters')\n",
      "train time: 57.610s\n",
      "Reg_Log_TF-IDF('lemmatization', 'pruning10')\n",
      "train time: 57.968s\n",
      "Reg_Log_TF-IDF('lemmatization', 'pruning5')\n",
      "train time: 56.283s\n",
      "Reg_Log_TF-IDF('urls', 'norm_letters')\n",
      "train time: 56.378s\n",
      "Reg_Log_TF-IDF('urls', 'pruning10')\n",
      "train time: 58.078s\n",
      "Reg_Log_TF-IDF('urls', 'pruning5')\n",
      "train time: 57.108s\n",
      "Reg_Log_TF-IDF('norm_letters', 'pruning10')\n",
      "train time: 57.506s\n",
      "Reg_Log_TF-IDF('norm_letters', 'pruning5')\n",
      "train time: 58.385s\n",
      "Reg_Log_TF-IDF('stop_words', 'stemming', 'urls')\n",
      "train time: 57.418s\n",
      "Reg_Log_TF-IDF('stop_words', 'stemming', 'norm_letters')\n",
      "train time: 58.587s\n",
      "Reg_Log_TF-IDF('stop_words', 'stemming', 'pruning10')\n",
      "train time: 58.671s\n",
      "Reg_Log_TF-IDF('stop_words', 'stemming', 'pruning5')\n",
      "train time: 57.749s\n",
      "Reg_Log_TF-IDF('stop_words', 'lemmatization', 'urls')\n",
      "train time: 57.052s\n",
      "Reg_Log_TF-IDF('stop_words', 'lemmatization', 'norm_letters')\n",
      "train time: 57.085s\n",
      "Reg_Log_TF-IDF('stop_words', 'lemmatization', 'pruning10')\n",
      "train time: 57.566s\n",
      "Reg_Log_TF-IDF('stop_words', 'lemmatization', 'pruning5')\n",
      "train time: 59.272s\n",
      "Reg_Log_TF-IDF('stop_words', 'urls', 'norm_letters')\n",
      "train time: 59.139s\n",
      "Reg_Log_TF-IDF('stop_words', 'urls', 'pruning10')\n",
      "train time: 59.337s\n",
      "Reg_Log_TF-IDF('stop_words', 'urls', 'pruning5')\n",
      "train time: 59.384s\n",
      "Reg_Log_TF-IDF('stop_words', 'norm_letters', 'pruning10')\n",
      "train time: 59.409s\n",
      "Reg_Log_TF-IDF('stop_words', 'norm_letters', 'pruning5')\n",
      "train time: 58.583s\n",
      "Reg_Log_TF-IDF('stemming', 'urls', 'norm_letters')\n",
      "train time: 60.097s\n",
      "Reg_Log_TF-IDF('stemming', 'urls', 'pruning10')\n",
      "train time: 60.060s\n",
      "Reg_Log_TF-IDF('stemming', 'urls', 'pruning5')\n",
      "train time: 60.040s\n",
      "Reg_Log_TF-IDF('stemming', 'norm_letters', 'pruning10')\n",
      "train time: 58.925s\n",
      "Reg_Log_TF-IDF('stemming', 'norm_letters', 'pruning5')\n",
      "train time: 58.891s\n",
      "Reg_Log_TF-IDF('lemmatization', 'urls', 'norm_letters')\n",
      "train time: 59.325s\n",
      "Reg_Log_TF-IDF('lemmatization', 'urls', 'pruning10')\n",
      "train time: 58.890s\n",
      "Reg_Log_TF-IDF('lemmatization', 'urls', 'pruning5')\n",
      "train time: 60.379s\n",
      "Reg_Log_TF-IDF('lemmatization', 'norm_letters', 'pruning10')\n",
      "train time: 60.622s\n",
      "Reg_Log_TF-IDF('lemmatization', 'norm_letters', 'pruning5')\n",
      "train time: 58.683s\n",
      "Reg_Log_TF-IDF('urls', 'norm_letters', 'pruning10')\n",
      "train time: 59.194s\n",
      "Reg_Log_TF-IDF('urls', 'norm_letters', 'pruning5')\n",
      "train time: 59.410s\n",
      "Reg_Log_TF-IDF('stop_words', 'stemming', 'urls', 'norm_letters')\n",
      "train time: 61.042s\n",
      "Reg_Log_TF-IDF('stop_words', 'stemming', 'urls', 'pruning10')\n",
      "train time: 59.176s\n",
      "Reg_Log_TF-IDF('stop_words', 'stemming', 'urls', 'pruning5')\n",
      "train time: 61.274s\n",
      "Reg_Log_TF-IDF('stop_words', 'stemming', 'norm_letters', 'pruning10')\n",
      "train time: 60.923s\n",
      "Reg_Log_TF-IDF('stop_words', 'stemming', 'norm_letters', 'pruning5')\n",
      "train time: 59.419s\n",
      "Reg_Log_TF-IDF('stop_words', 'lemmatization', 'urls', 'norm_letters')\n",
      "train time: 59.323s\n",
      "Reg_Log_TF-IDF('stop_words', 'lemmatization', 'urls', 'pruning10')\n",
      "train time: 59.902s\n",
      "Reg_Log_TF-IDF('stop_words', 'lemmatization', 'urls', 'pruning5')\n",
      "train time: 61.477s\n",
      "Reg_Log_TF-IDF('stop_words', 'lemmatization', 'norm_letters', 'pruning10')\n",
      "train time: 59.739s\n",
      "Reg_Log_TF-IDF('stop_words', 'lemmatization', 'norm_letters', 'pruning5')\n",
      "train time: 60.090s\n",
      "Reg_Log_TF-IDF('stop_words', 'urls', 'norm_letters', 'pruning10')\n",
      "train time: 60.652s\n",
      "Reg_Log_TF-IDF('stop_words', 'urls', 'norm_letters', 'pruning5')\n",
      "train time: 60.132s\n",
      "Reg_Log_TF-IDF('stemming', 'urls', 'norm_letters', 'pruning10')\n",
      "train time: 62.272s\n",
      "Reg_Log_TF-IDF('stemming', 'urls', 'norm_letters', 'pruning5')\n",
      "train time: 60.479s\n",
      "Reg_Log_TF-IDF('lemmatization', 'urls', 'norm_letters', 'pruning10')\n",
      "train time: 60.085s\n",
      "Reg_Log_TF-IDF('lemmatization', 'urls', 'norm_letters', 'pruning5')\n",
      "train time: 60.992s\n",
      "Reg_Log_TF-IDF('stop_words', 'stemming', 'urls', 'norm_letters', 'pruning10')\n",
      "train time: 62.314s\n",
      "Reg_Log_TF-IDF('stop_words', 'stemming', 'urls', 'norm_letters', 'pruning5')\n",
      "train time: 62.640s\n",
      "Reg_Log_TF-IDF('stop_words', 'lemmatization', 'urls', 'norm_letters', 'pruning10')\n",
      "train time: 60.720s\n",
      "Reg_Log_TF-IDF('stop_words', 'lemmatization', 'urls', 'norm_letters', 'pruning5')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 62.529s\n",
      "Reg_Log_Binario('stop_words',)\n",
      "train time: 60.879s\n",
      "Reg_Log_Binario('stemming',)\n",
      "train time: 64.157s\n",
      "Reg_Log_Binario('lemmatization',)\n",
      "train time: 63.935s\n",
      "Reg_Log_Binario('urls',)\n",
      "train time: 64.340s\n",
      "Reg_Log_Binario('norm_letters',)\n",
      "train time: 64.409s\n",
      "Reg_Log_Binario('pruning10',)\n",
      "train time: 62.135s\n",
      "Reg_Log_Binario('pruning5',)\n",
      "train time: 64.082s\n",
      "Reg_Log_Binario('stop_words', 'stemming')\n",
      "train time: 64.056s\n",
      "Reg_Log_Binario('stop_words', 'lemmatization')\n",
      "train time: 64.224s\n",
      "Reg_Log_Binario('stop_words', 'urls')\n",
      "train time: 64.242s\n",
      "Reg_Log_Binario('stop_words', 'norm_letters')\n",
      "train time: 64.315s\n",
      "Reg_Log_Binario('stop_words', 'pruning10')\n",
      "train time: 63.976s\n",
      "Reg_Log_Binario('stop_words', 'pruning5')\n",
      "train time: 63.888s\n",
      "Reg_Log_Binario('stemming', 'urls')\n",
      "train time: 63.495s\n",
      "Reg_Log_Binario('stemming', 'norm_letters')\n",
      "train time: 65.236s\n",
      "Reg_Log_Binario('stemming', 'pruning10')\n",
      "train time: 64.759s\n",
      "Reg_Log_Binario('stemming', 'pruning5')\n",
      "train time: 64.824s\n",
      "Reg_Log_Binario('lemmatization', 'urls')\n",
      "train time: 65.334s\n",
      "Reg_Log_Binario('lemmatization', 'norm_letters')\n",
      "train time: 65.811s\n",
      "Reg_Log_Binario('lemmatization', 'pruning10')\n",
      "train time: 65.256s\n",
      "Reg_Log_Binario('lemmatization', 'pruning5')\n",
      "train time: 65.510s\n",
      "Reg_Log_Binario('urls', 'norm_letters')\n",
      "train time: 64.816s\n",
      "Reg_Log_Binario('urls', 'pruning10')\n",
      "train time: 64.449s\n",
      "Reg_Log_Binario('urls', 'pruning5')\n",
      "train time: 65.888s\n",
      "Reg_Log_Binario('norm_letters', 'pruning10')\n",
      "train time: 64.337s\n",
      "Reg_Log_Binario('norm_letters', 'pruning5')\n",
      "train time: 66.637s\n",
      "Reg_Log_Binario('stop_words', 'stemming', 'urls')\n",
      "train time: 65.881s\n",
      "Reg_Log_Binario('stop_words', 'stemming', 'norm_letters')\n",
      "train time: 66.591s\n",
      "Reg_Log_Binario('stop_words', 'stemming', 'pruning10')\n",
      "train time: 64.554s\n",
      "Reg_Log_Binario('stop_words', 'stemming', 'pruning5')\n",
      "train time: 64.625s\n",
      "Reg_Log_Binario('stop_words', 'lemmatization', 'urls')\n",
      "train time: 66.419s\n",
      "Reg_Log_Binario('stop_words', 'lemmatization', 'norm_letters')\n",
      "train time: 65.329s\n",
      "Reg_Log_Binario('stop_words', 'lemmatization', 'pruning10')\n",
      "train time: 64.544s\n",
      "Reg_Log_Binario('stop_words', 'lemmatization', 'pruning5')\n",
      "train time: 66.924s\n",
      "Reg_Log_Binario('stop_words', 'urls', 'norm_letters')\n",
      "train time: 65.481s\n",
      "Reg_Log_Binario('stop_words', 'urls', 'pruning10')\n",
      "train time: 65.245s\n",
      "Reg_Log_Binario('stop_words', 'urls', 'pruning5')\n",
      "train time: 65.539s\n",
      "Reg_Log_Binario('stop_words', 'norm_letters', 'pruning10')\n",
      "train time: 65.522s\n",
      "Reg_Log_Binario('stop_words', 'norm_letters', 'pruning5')\n",
      "train time: 66.279s\n",
      "Reg_Log_Binario('stemming', 'urls', 'norm_letters')\n",
      "train time: 65.738s\n",
      "Reg_Log_Binario('stemming', 'urls', 'pruning10')\n",
      "train time: 66.341s\n",
      "Reg_Log_Binario('stemming', 'urls', 'pruning5')\n",
      "train time: 68.329s\n",
      "Reg_Log_Binario('stemming', 'norm_letters', 'pruning10')\n",
      "train time: 67.144s\n",
      "Reg_Log_Binario('stemming', 'norm_letters', 'pruning5')\n",
      "train time: 68.360s\n",
      "Reg_Log_Binario('lemmatization', 'urls', 'norm_letters')\n",
      "train time: 68.936s\n",
      "Reg_Log_Binario('lemmatization', 'urls', 'pruning10')\n",
      "train time: 68.016s\n",
      "Reg_Log_Binario('lemmatization', 'urls', 'pruning5')\n",
      "train time: 67.216s\n",
      "Reg_Log_Binario('lemmatization', 'norm_letters', 'pruning10')\n",
      "train time: 66.896s\n",
      "Reg_Log_Binario('lemmatization', 'norm_letters', 'pruning5')\n",
      "train time: 66.937s\n",
      "Reg_Log_Binario('urls', 'norm_letters', 'pruning10')\n",
      "train time: 66.431s\n",
      "Reg_Log_Binario('urls', 'norm_letters', 'pruning5')\n",
      "train time: 67.734s\n",
      "Reg_Log_Binario('stop_words', 'stemming', 'urls', 'norm_letters')\n",
      "train time: 67.347s\n",
      "Reg_Log_Binario('stop_words', 'stemming', 'urls', 'pruning10')\n",
      "train time: 66.767s\n",
      "Reg_Log_Binario('stop_words', 'stemming', 'urls', 'pruning5')\n",
      "train time: 72.530s\n",
      "Reg_Log_Binario('stop_words', 'stemming', 'norm_letters', 'pruning10')\n",
      "train time: 72.730s\n",
      "Reg_Log_Binario('stop_words', 'stemming', 'norm_letters', 'pruning5')\n",
      "train time: 73.135s\n",
      "Reg_Log_Binario('stop_words', 'lemmatization', 'urls', 'norm_letters')\n",
      "train time: 72.566s\n",
      "Reg_Log_Binario('stop_words', 'lemmatization', 'urls', 'pruning10')\n",
      "train time: 69.061s\n",
      "Reg_Log_Binario('stop_words', 'lemmatization', 'urls', 'pruning5')\n",
      "train time: 69.199s\n",
      "Reg_Log_Binario('stop_words', 'lemmatization', 'norm_letters', 'pruning10')\n",
      "train time: 67.251s\n",
      "Reg_Log_Binario('stop_words', 'lemmatization', 'norm_letters', 'pruning5')\n",
      "train time: 67.598s\n",
      "Reg_Log_Binario('stop_words', 'urls', 'norm_letters', 'pruning10')\n",
      "train time: 68.270s\n",
      "Reg_Log_Binario('stop_words', 'urls', 'norm_letters', 'pruning5')\n",
      "train time: 67.291s\n",
      "Reg_Log_Binario('stemming', 'urls', 'norm_letters', 'pruning10')\n",
      "train time: 69.047s\n",
      "Reg_Log_Binario('lemmatization', 'urls', 'norm_letters', 'pruning10')\n",
      "train time: 69.860s\n",
      "Reg_Log_Binario('lemmatization', 'urls', 'norm_letters', 'pruning5')\n",
      "train time: 68.332s\n",
      "Reg_Log_Binario('stop_words', 'stemming', 'urls', 'norm_letters', 'pruning10')\n",
      "train time: 69.726s\n",
      "Reg_Log_Binario('stop_words', 'stemming', 'urls', 'norm_letters', 'pruning5')\n",
      "train time: 69.710s\n",
      "Reg_Log_Binario('stop_words', 'lemmatization', 'urls', 'norm_letters', 'pruning10')\n",
      "train time: 68.934s\n",
      "Reg_Log_Binario('stop_words', 'lemmatization', 'urls', 'norm_letters', 'pruning5')\n",
      "train time: 68.466s\n"
     ]
    }
   ],
   "source": [
    "vectorizers_list = []\n",
    "results_list = []\n",
    "workbook = xlsxwriter.Workbook('result_combinations_tweets.xlsx')\n",
    "for clf_type_weighting_type in clf_types_weighting_types:\n",
    "    ws_name = clf_type_weighting_type['clf_name'] + '_' + clf_type_weighting_type['weighting_type']\n",
    "    worksheet = workbook.add_worksheet(ws_name)\n",
    "    init_row = 0\n",
    "    for comb in all_the_tasks:\n",
    "        \n",
    "        if clf_type_weighting_type['weighting_type'] == 'TF':\n",
    "            vectorizer = CountVectorizer()\n",
    "        if clf_type_weighting_type['weighting_type'] == 'TF-IDF':\n",
    "            vectorizer = TfidfVectorizer()\n",
    "        if clf_type_weighting_type['weighting_type'] == 'Binario':\n",
    "            vectorizer = CountVectorizer(binary=True)\n",
    "        \n",
    "        clf_type = clf_type_weighting_type['clf_type']\n",
    "        optimal_parameters = clf_type_weighting_type['optimal_parameters']\n",
    "        random_state = clf_type_weighting_type['random_state']\n",
    "        \n",
    "        def tokenize_combinations(text):\n",
    "            if ('urls' in comb):\n",
    "                url_regex = 'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
    "                text = re.sub(url_regex, '', text, flags=re.MULTILINE)\n",
    "\n",
    "            regexp_tokenizer = RegexpTokenizer(u'(?u)\\\\b\\\\w\\\\w+\\\\b')\n",
    "            tokens =  regexp_tokenizer.tokenize(text)\n",
    "\n",
    "            if ('norm_letters' in comb):\n",
    "                tokens = norm_repeated_letters(tokens, replacer)\n",
    "\n",
    "            if ('stemming' in comb):\n",
    "                tokens = stem_tokens(tokens, stemmer)\n",
    "\n",
    "            if ('lemmatization' in comb):\n",
    "                tokens = lemmatizer(tokens)\n",
    "\n",
    "            return tokens\n",
    "\n",
    "        vectorizer.set_params(tokenizer = tokenize_combinations)\n",
    "        \n",
    "        if ('stop_words' in comb):\n",
    "            vectorizer.set_params(stop_words = spanish_stopwords)\n",
    "            \n",
    "        if ('pruning10' in comb):\n",
    "            vectorizer.set_params(min_df=10)\n",
    "            \n",
    "        if ('pruning5' in comb):\n",
    "            vectorizer.set_params(min_df=5)\n",
    "            \n",
    "        print(ws_name + str(comb))\n",
    "        exp_results = run_one_comb_experiment(total_data_content, total_data_target, vectorizer, optimal_parameters, clf_type, random_state)\n",
    "        continue_row = save_excel_comb_results(worksheet, init_row, exp_results, str(optimal_parameters), random_state, str(comb))\n",
    "        init_row = continue_row\n",
    "        vectorizers_list.append(vectorizer)\n",
    "        results_list.append(exp_results + (ws_name, str(comb)))\n",
    "workbook.close()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9108018207282913,\n",
       " 5987,\n",
       " 0.9079317998182008,\n",
       " 0.9088661072868451,\n",
       " 0.9070698246507669,\n",
       " 6211,\n",
       " 4194,\n",
       " 544,\n",
       " 475,\n",
       " 'SVM_lineal_TF',\n",
       " \"('lemmatization', 'norm_letters', 'pruning5')\")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(results_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "639"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_list_backup = results_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.868873</td>\n",
       "      <td>48099</td>\n",
       "      <td>0.864606</td>\n",
       "      <td>0.865588</td>\n",
       "      <td>0.863716</td>\n",
       "      <td>5977</td>\n",
       "      <td>3949</td>\n",
       "      <td>789</td>\n",
       "      <td>709</td>\n",
       "      <td>Bayesiano_TF</td>\n",
       "      <td>('stop_words',)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.872286</td>\n",
       "      <td>32900</td>\n",
       "      <td>0.869419</td>\n",
       "      <td>0.867375</td>\n",
       "      <td>0.872382</td>\n",
       "      <td>5829</td>\n",
       "      <td>4136</td>\n",
       "      <td>602</td>\n",
       "      <td>857</td>\n",
       "      <td>Bayesiano_TF</td>\n",
       "      <td>('stemming',)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.873162</td>\n",
       "      <td>36795</td>\n",
       "      <td>0.870209</td>\n",
       "      <td>0.868315</td>\n",
       "      <td>0.872822</td>\n",
       "      <td>5849</td>\n",
       "      <td>4126</td>\n",
       "      <td>612</td>\n",
       "      <td>837</td>\n",
       "      <td>Bayesiano_TF</td>\n",
       "      <td>('lemmatization',)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.873687</td>\n",
       "      <td>40405</td>\n",
       "      <td>0.870782</td>\n",
       "      <td>0.868830</td>\n",
       "      <td>0.873517</td>\n",
       "      <td>5847</td>\n",
       "      <td>4134</td>\n",
       "      <td>604</td>\n",
       "      <td>839</td>\n",
       "      <td>Bayesiano_TF</td>\n",
       "      <td>('urls',)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.874475</td>\n",
       "      <td>47550</td>\n",
       "      <td>0.871272</td>\n",
       "      <td>0.869888</td>\n",
       "      <td>0.872960</td>\n",
       "      <td>5896</td>\n",
       "      <td>4094</td>\n",
       "      <td>644</td>\n",
       "      <td>790</td>\n",
       "      <td>Bayesiano_TF</td>\n",
       "      <td>('norm_letters',)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0      1         2         3         4     5     6    7    8   \\\n",
       "0  0.868873  48099  0.864606  0.865588  0.863716  5977  3949  789  709   \n",
       "1  0.872286  32900  0.869419  0.867375  0.872382  5829  4136  602  857   \n",
       "2  0.873162  36795  0.870209  0.868315  0.872822  5849  4126  612  837   \n",
       "3  0.873687  40405  0.870782  0.868830  0.873517  5847  4134  604  839   \n",
       "4  0.874475  47550  0.871272  0.869888  0.872960  5896  4094  644  790   \n",
       "\n",
       "             9                   10  \n",
       "0  Bayesiano_TF     ('stop_words',)  \n",
       "1  Bayesiano_TF       ('stemming',)  \n",
       "2  Bayesiano_TF  ('lemmatization',)  \n",
       "3  Bayesiano_TF           ('urls',)  \n",
       "4  Bayesiano_TF   ('norm_letters',)  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = results_df[[9, 10, 1, 0, 2, 3, 4, 5, 6, 7, 8]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bayesiano_TF</td>\n",
       "      <td>('stop_words',)</td>\n",
       "      <td>48099</td>\n",
       "      <td>0.868873</td>\n",
       "      <td>0.864606</td>\n",
       "      <td>0.865588</td>\n",
       "      <td>0.863716</td>\n",
       "      <td>5977</td>\n",
       "      <td>3949</td>\n",
       "      <td>789</td>\n",
       "      <td>709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bayesiano_TF</td>\n",
       "      <td>('stemming',)</td>\n",
       "      <td>32900</td>\n",
       "      <td>0.872286</td>\n",
       "      <td>0.869419</td>\n",
       "      <td>0.867375</td>\n",
       "      <td>0.872382</td>\n",
       "      <td>5829</td>\n",
       "      <td>4136</td>\n",
       "      <td>602</td>\n",
       "      <td>857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bayesiano_TF</td>\n",
       "      <td>('lemmatization',)</td>\n",
       "      <td>36795</td>\n",
       "      <td>0.873162</td>\n",
       "      <td>0.870209</td>\n",
       "      <td>0.868315</td>\n",
       "      <td>0.872822</td>\n",
       "      <td>5849</td>\n",
       "      <td>4126</td>\n",
       "      <td>612</td>\n",
       "      <td>837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bayesiano_TF</td>\n",
       "      <td>('urls',)</td>\n",
       "      <td>40405</td>\n",
       "      <td>0.873687</td>\n",
       "      <td>0.870782</td>\n",
       "      <td>0.868830</td>\n",
       "      <td>0.873517</td>\n",
       "      <td>5847</td>\n",
       "      <td>4134</td>\n",
       "      <td>604</td>\n",
       "      <td>839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bayesiano_TF</td>\n",
       "      <td>('norm_letters',)</td>\n",
       "      <td>47550</td>\n",
       "      <td>0.874475</td>\n",
       "      <td>0.871272</td>\n",
       "      <td>0.869888</td>\n",
       "      <td>0.872960</td>\n",
       "      <td>5896</td>\n",
       "      <td>4094</td>\n",
       "      <td>644</td>\n",
       "      <td>790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bayesiano_TF</td>\n",
       "      <td>('pruning10',)</td>\n",
       "      <td>4348</td>\n",
       "      <td>0.863708</td>\n",
       "      <td>0.861047</td>\n",
       "      <td>0.858698</td>\n",
       "      <td>0.865268</td>\n",
       "      <td>5724</td>\n",
       "      <td>4143</td>\n",
       "      <td>595</td>\n",
       "      <td>962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bayesiano_TF</td>\n",
       "      <td>('pruning5',)</td>\n",
       "      <td>7822</td>\n",
       "      <td>0.868610</td>\n",
       "      <td>0.866004</td>\n",
       "      <td>0.863641</td>\n",
       "      <td>0.870133</td>\n",
       "      <td>5758</td>\n",
       "      <td>4165</td>\n",
       "      <td>573</td>\n",
       "      <td>928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Bayesiano_TF</td>\n",
       "      <td>('stop_words', 'stemming')</td>\n",
       "      <td>32814</td>\n",
       "      <td>0.872024</td>\n",
       "      <td>0.868328</td>\n",
       "      <td>0.867958</td>\n",
       "      <td>0.868714</td>\n",
       "      <td>5938</td>\n",
       "      <td>4024</td>\n",
       "      <td>714</td>\n",
       "      <td>748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Bayesiano_TF</td>\n",
       "      <td>('stop_words', 'lemmatization')</td>\n",
       "      <td>36731</td>\n",
       "      <td>0.871148</td>\n",
       "      <td>0.867427</td>\n",
       "      <td>0.867058</td>\n",
       "      <td>0.867812</td>\n",
       "      <td>5933</td>\n",
       "      <td>4019</td>\n",
       "      <td>719</td>\n",
       "      <td>753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Bayesiano_TF</td>\n",
       "      <td>('stop_words', 'urls')</td>\n",
       "      <td>40155</td>\n",
       "      <td>0.871236</td>\n",
       "      <td>0.867608</td>\n",
       "      <td>0.867007</td>\n",
       "      <td>0.868256</td>\n",
       "      <td>5922</td>\n",
       "      <td>4031</td>\n",
       "      <td>707</td>\n",
       "      <td>764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Bayesiano_TF</td>\n",
       "      <td>('stop_words', 'norm_letters')</td>\n",
       "      <td>47300</td>\n",
       "      <td>0.869748</td>\n",
       "      <td>0.865475</td>\n",
       "      <td>0.866568</td>\n",
       "      <td>0.864494</td>\n",
       "      <td>5986</td>\n",
       "      <td>3950</td>\n",
       "      <td>788</td>\n",
       "      <td>700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Bayesiano_TF</td>\n",
       "      <td>('stop_words', 'pruning10')</td>\n",
       "      <td>4163</td>\n",
       "      <td>0.858368</td>\n",
       "      <td>0.854804</td>\n",
       "      <td>0.853401</td>\n",
       "      <td>0.856556</td>\n",
       "      <td>5798</td>\n",
       "      <td>4008</td>\n",
       "      <td>730</td>\n",
       "      <td>888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Bayesiano_TF</td>\n",
       "      <td>('stop_words', 'pruning5')</td>\n",
       "      <td>7615</td>\n",
       "      <td>0.863095</td>\n",
       "      <td>0.859642</td>\n",
       "      <td>0.858232</td>\n",
       "      <td>0.861394</td>\n",
       "      <td>5826</td>\n",
       "      <td>4034</td>\n",
       "      <td>704</td>\n",
       "      <td>860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Bayesiano_TF</td>\n",
       "      <td>('stemming', 'urls')</td>\n",
       "      <td>24956</td>\n",
       "      <td>0.870886</td>\n",
       "      <td>0.868410</td>\n",
       "      <td>0.865979</td>\n",
       "      <td>0.872876</td>\n",
       "      <td>5758</td>\n",
       "      <td>4191</td>\n",
       "      <td>547</td>\n",
       "      <td>928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Bayesiano_TF</td>\n",
       "      <td>('stemming', 'norm_letters')</td>\n",
       "      <td>32097</td>\n",
       "      <td>0.872637</td>\n",
       "      <td>0.869749</td>\n",
       "      <td>0.867742</td>\n",
       "      <td>0.872620</td>\n",
       "      <td>5835</td>\n",
       "      <td>4134</td>\n",
       "      <td>604</td>\n",
       "      <td>851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Bayesiano_TF</td>\n",
       "      <td>('stemming', 'pruning10')</td>\n",
       "      <td>3579</td>\n",
       "      <td>0.869660</td>\n",
       "      <td>0.867002</td>\n",
       "      <td>0.864685</td>\n",
       "      <td>0.870876</td>\n",
       "      <td>5775</td>\n",
       "      <td>4160</td>\n",
       "      <td>578</td>\n",
       "      <td>911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Bayesiano_TF</td>\n",
       "      <td>('stemming', 'pruning5')</td>\n",
       "      <td>5712</td>\n",
       "      <td>0.870536</td>\n",
       "      <td>0.867876</td>\n",
       "      <td>0.865569</td>\n",
       "      <td>0.871686</td>\n",
       "      <td>5783</td>\n",
       "      <td>4162</td>\n",
       "      <td>576</td>\n",
       "      <td>903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Bayesiano_TF</td>\n",
       "      <td>('lemmatization', 'urls')</td>\n",
       "      <td>28850</td>\n",
       "      <td>0.872899</td>\n",
       "      <td>0.870278</td>\n",
       "      <td>0.867962</td>\n",
       "      <td>0.874074</td>\n",
       "      <td>5798</td>\n",
       "      <td>4174</td>\n",
       "      <td>564</td>\n",
       "      <td>888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Bayesiano_TF</td>\n",
       "      <td>('lemmatization', 'norm_letters')</td>\n",
       "      <td>36091</td>\n",
       "      <td>0.872637</td>\n",
       "      <td>0.869679</td>\n",
       "      <td>0.867777</td>\n",
       "      <td>0.872312</td>\n",
       "      <td>5845</td>\n",
       "      <td>4124</td>\n",
       "      <td>614</td>\n",
       "      <td>841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Bayesiano_TF</td>\n",
       "      <td>('lemmatization', 'pruning10')</td>\n",
       "      <td>3592</td>\n",
       "      <td>0.869048</td>\n",
       "      <td>0.866326</td>\n",
       "      <td>0.864058</td>\n",
       "      <td>0.870015</td>\n",
       "      <td>5779</td>\n",
       "      <td>4149</td>\n",
       "      <td>589</td>\n",
       "      <td>907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Bayesiano_TF</td>\n",
       "      <td>('lemmatization', 'pruning5')</td>\n",
       "      <td>6002</td>\n",
       "      <td>0.870798</td>\n",
       "      <td>0.868133</td>\n",
       "      <td>0.865834</td>\n",
       "      <td>0.871910</td>\n",
       "      <td>5786</td>\n",
       "      <td>4162</td>\n",
       "      <td>576</td>\n",
       "      <td>900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Bayesiano_TF</td>\n",
       "      <td>('urls', 'norm_letters')</td>\n",
       "      <td>39606</td>\n",
       "      <td>0.874125</td>\n",
       "      <td>0.871212</td>\n",
       "      <td>0.869285</td>\n",
       "      <td>0.873891</td>\n",
       "      <td>5852</td>\n",
       "      <td>4134</td>\n",
       "      <td>604</td>\n",
       "      <td>834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Bayesiano_TF</td>\n",
       "      <td>('urls', 'pruning10')</td>\n",
       "      <td>4337</td>\n",
       "      <td>0.863708</td>\n",
       "      <td>0.861195</td>\n",
       "      <td>0.858790</td>\n",
       "      <td>0.865945</td>\n",
       "      <td>5702</td>\n",
       "      <td>4165</td>\n",
       "      <td>573</td>\n",
       "      <td>984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Bayesiano_TF</td>\n",
       "      <td>('urls', 'pruning5')</td>\n",
       "      <td>7812</td>\n",
       "      <td>0.868610</td>\n",
       "      <td>0.866104</td>\n",
       "      <td>0.863685</td>\n",
       "      <td>0.870594</td>\n",
       "      <td>5743</td>\n",
       "      <td>4180</td>\n",
       "      <td>558</td>\n",
       "      <td>943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Bayesiano_TF</td>\n",
       "      <td>('norm_letters', 'pruning10')</td>\n",
       "      <td>4349</td>\n",
       "      <td>0.863445</td>\n",
       "      <td>0.860817</td>\n",
       "      <td>0.858452</td>\n",
       "      <td>0.865167</td>\n",
       "      <td>5717</td>\n",
       "      <td>4147</td>\n",
       "      <td>591</td>\n",
       "      <td>969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Bayesiano_TF</td>\n",
       "      <td>('norm_letters', 'pruning5')</td>\n",
       "      <td>7822</td>\n",
       "      <td>0.868697</td>\n",
       "      <td>0.866117</td>\n",
       "      <td>0.863738</td>\n",
       "      <td>0.870330</td>\n",
       "      <td>5755</td>\n",
       "      <td>4169</td>\n",
       "      <td>569</td>\n",
       "      <td>931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Bayesiano_TF</td>\n",
       "      <td>('stop_words', 'stemming', 'urls')</td>\n",
       "      <td>24870</td>\n",
       "      <td>0.870886</td>\n",
       "      <td>0.867662</td>\n",
       "      <td>0.866155</td>\n",
       "      <td>0.869556</td>\n",
       "      <td>5866</td>\n",
       "      <td>4083</td>\n",
       "      <td>655</td>\n",
       "      <td>820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Bayesiano_TF</td>\n",
       "      <td>('stop_words', 'stemming', 'norm_letters')</td>\n",
       "      <td>32012</td>\n",
       "      <td>0.871324</td>\n",
       "      <td>0.867575</td>\n",
       "      <td>0.867290</td>\n",
       "      <td>0.867870</td>\n",
       "      <td>5938</td>\n",
       "      <td>4016</td>\n",
       "      <td>722</td>\n",
       "      <td>748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Bayesiano_TF</td>\n",
       "      <td>('stop_words', 'stemming', 'pruning10')</td>\n",
       "      <td>3500</td>\n",
       "      <td>0.864758</td>\n",
       "      <td>0.861490</td>\n",
       "      <td>0.859828</td>\n",
       "      <td>0.863675</td>\n",
       "      <td>5817</td>\n",
       "      <td>4062</td>\n",
       "      <td>676</td>\n",
       "      <td>869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Bayesiano_TF</td>\n",
       "      <td>('stop_words', 'stemming', 'pruning5')</td>\n",
       "      <td>5631</td>\n",
       "      <td>0.868172</td>\n",
       "      <td>0.865063</td>\n",
       "      <td>0.863259</td>\n",
       "      <td>0.867514</td>\n",
       "      <td>5826</td>\n",
       "      <td>4092</td>\n",
       "      <td>646</td>\n",
       "      <td>860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>Reg_Log_Binario</td>\n",
       "      <td>('stemming', 'urls', 'pruning5')</td>\n",
       "      <td>5701</td>\n",
       "      <td>0.907563</td>\n",
       "      <td>0.904658</td>\n",
       "      <td>0.905261</td>\n",
       "      <td>0.904088</td>\n",
       "      <td>6181</td>\n",
       "      <td>4187</td>\n",
       "      <td>551</td>\n",
       "      <td>505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>Reg_Log_Binario</td>\n",
       "      <td>('stemming', 'norm_letters', 'pruning10')</td>\n",
       "      <td>3578</td>\n",
       "      <td>0.905287</td>\n",
       "      <td>0.902317</td>\n",
       "      <td>0.902889</td>\n",
       "      <td>0.901774</td>\n",
       "      <td>6167</td>\n",
       "      <td>4175</td>\n",
       "      <td>563</td>\n",
       "      <td>519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>Reg_Log_Binario</td>\n",
       "      <td>('stemming', 'norm_letters', 'pruning5')</td>\n",
       "      <td>5722</td>\n",
       "      <td>0.907213</td>\n",
       "      <td>0.904309</td>\n",
       "      <td>0.904857</td>\n",
       "      <td>0.903788</td>\n",
       "      <td>6177</td>\n",
       "      <td>4187</td>\n",
       "      <td>551</td>\n",
       "      <td>509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>Reg_Log_Binario</td>\n",
       "      <td>('lemmatization', 'urls', 'norm_letters')</td>\n",
       "      <td>28146</td>\n",
       "      <td>0.909664</td>\n",
       "      <td>0.906706</td>\n",
       "      <td>0.907889</td>\n",
       "      <td>0.905636</td>\n",
       "      <td>6213</td>\n",
       "      <td>4179</td>\n",
       "      <td>559</td>\n",
       "      <td>473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>Reg_Log_Binario</td>\n",
       "      <td>('lemmatization', 'urls', 'pruning10')</td>\n",
       "      <td>3582</td>\n",
       "      <td>0.905200</td>\n",
       "      <td>0.902074</td>\n",
       "      <td>0.903348</td>\n",
       "      <td>0.900931</td>\n",
       "      <td>6191</td>\n",
       "      <td>4150</td>\n",
       "      <td>588</td>\n",
       "      <td>495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>Reg_Log_Binario</td>\n",
       "      <td>('lemmatization', 'urls', 'pruning5')</td>\n",
       "      <td>5991</td>\n",
       "      <td>0.908263</td>\n",
       "      <td>0.905296</td>\n",
       "      <td>0.906298</td>\n",
       "      <td>0.904378</td>\n",
       "      <td>6199</td>\n",
       "      <td>4177</td>\n",
       "      <td>561</td>\n",
       "      <td>487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>Reg_Log_Binario</td>\n",
       "      <td>('lemmatization', 'norm_letters', 'pruning10')</td>\n",
       "      <td>3589</td>\n",
       "      <td>0.905375</td>\n",
       "      <td>0.902267</td>\n",
       "      <td>0.903482</td>\n",
       "      <td>0.901173</td>\n",
       "      <td>6190</td>\n",
       "      <td>4153</td>\n",
       "      <td>585</td>\n",
       "      <td>496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>Reg_Log_Binario</td>\n",
       "      <td>('lemmatization', 'norm_letters', 'pruning5')</td>\n",
       "      <td>5987</td>\n",
       "      <td>0.908001</td>\n",
       "      <td>0.905034</td>\n",
       "      <td>0.905991</td>\n",
       "      <td>0.904154</td>\n",
       "      <td>6196</td>\n",
       "      <td>4177</td>\n",
       "      <td>561</td>\n",
       "      <td>490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>Reg_Log_Binario</td>\n",
       "      <td>('urls', 'norm_letters', 'pruning10')</td>\n",
       "      <td>4339</td>\n",
       "      <td>0.895571</td>\n",
       "      <td>0.892286</td>\n",
       "      <td>0.892884</td>\n",
       "      <td>0.891721</td>\n",
       "      <td>6113</td>\n",
       "      <td>4118</td>\n",
       "      <td>620</td>\n",
       "      <td>573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>Reg_Log_Binario</td>\n",
       "      <td>('urls', 'norm_letters', 'pruning5')</td>\n",
       "      <td>7810</td>\n",
       "      <td>0.902574</td>\n",
       "      <td>0.899515</td>\n",
       "      <td>0.900097</td>\n",
       "      <td>0.898964</td>\n",
       "      <td>6152</td>\n",
       "      <td>4159</td>\n",
       "      <td>579</td>\n",
       "      <td>534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>Reg_Log_Binario</td>\n",
       "      <td>('stop_words', 'stemming', 'urls', 'norm_lette...</td>\n",
       "      <td>24069</td>\n",
       "      <td>0.902836</td>\n",
       "      <td>0.899557</td>\n",
       "      <td>0.901175</td>\n",
       "      <td>0.898143</td>\n",
       "      <td>6189</td>\n",
       "      <td>4125</td>\n",
       "      <td>613</td>\n",
       "      <td>497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>Reg_Log_Binario</td>\n",
       "      <td>('stop_words', 'stemming', 'urls', 'pruning10')</td>\n",
       "      <td>3490</td>\n",
       "      <td>0.898897</td>\n",
       "      <td>0.895503</td>\n",
       "      <td>0.897027</td>\n",
       "      <td>0.894163</td>\n",
       "      <td>6164</td>\n",
       "      <td>4105</td>\n",
       "      <td>633</td>\n",
       "      <td>522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>Reg_Log_Binario</td>\n",
       "      <td>('stop_words', 'stemming', 'urls', 'pruning5')</td>\n",
       "      <td>5620</td>\n",
       "      <td>0.902486</td>\n",
       "      <td>0.899287</td>\n",
       "      <td>0.900478</td>\n",
       "      <td>0.898213</td>\n",
       "      <td>6173</td>\n",
       "      <td>4137</td>\n",
       "      <td>601</td>\n",
       "      <td>513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>Reg_Log_Binario</td>\n",
       "      <td>('stop_words', 'stemming', 'norm_letters', 'pr...</td>\n",
       "      <td>3500</td>\n",
       "      <td>0.898985</td>\n",
       "      <td>0.895610</td>\n",
       "      <td>0.897059</td>\n",
       "      <td>0.894330</td>\n",
       "      <td>6162</td>\n",
       "      <td>4108</td>\n",
       "      <td>630</td>\n",
       "      <td>524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>Reg_Log_Binario</td>\n",
       "      <td>('stop_words', 'stemming', 'norm_letters', 'pr...</td>\n",
       "      <td>5642</td>\n",
       "      <td>0.903536</td>\n",
       "      <td>0.900385</td>\n",
       "      <td>0.901520</td>\n",
       "      <td>0.899356</td>\n",
       "      <td>6177</td>\n",
       "      <td>4145</td>\n",
       "      <td>593</td>\n",
       "      <td>509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>Reg_Log_Binario</td>\n",
       "      <td>('stop_words', 'lemmatization', 'urls', 'norm_...</td>\n",
       "      <td>28081</td>\n",
       "      <td>0.902223</td>\n",
       "      <td>0.898827</td>\n",
       "      <td>0.900907</td>\n",
       "      <td>0.897066</td>\n",
       "      <td>6200</td>\n",
       "      <td>4107</td>\n",
       "      <td>631</td>\n",
       "      <td>486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>Reg_Log_Binario</td>\n",
       "      <td>('stop_words', 'lemmatization', 'urls', 'pruni...</td>\n",
       "      <td>3520</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.892240</td>\n",
       "      <td>0.894174</td>\n",
       "      <td>0.890592</td>\n",
       "      <td>6160</td>\n",
       "      <td>4074</td>\n",
       "      <td>664</td>\n",
       "      <td>526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>Reg_Log_Binario</td>\n",
       "      <td>('stop_words', 'lemmatization', 'urls', 'pruni...</td>\n",
       "      <td>5929</td>\n",
       "      <td>0.899947</td>\n",
       "      <td>0.896514</td>\n",
       "      <td>0.898387</td>\n",
       "      <td>0.894907</td>\n",
       "      <td>6181</td>\n",
       "      <td>4100</td>\n",
       "      <td>638</td>\n",
       "      <td>505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>Reg_Log_Binario</td>\n",
       "      <td>('stop_words', 'lemmatization', 'norm_letters'...</td>\n",
       "      <td>3526</td>\n",
       "      <td>0.893645</td>\n",
       "      <td>0.889907</td>\n",
       "      <td>0.892137</td>\n",
       "      <td>0.888046</td>\n",
       "      <td>6157</td>\n",
       "      <td>4052</td>\n",
       "      <td>686</td>\n",
       "      <td>529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>Reg_Log_Binario</td>\n",
       "      <td>('stop_words', 'lemmatization', 'norm_letters'...</td>\n",
       "      <td>5924</td>\n",
       "      <td>0.899860</td>\n",
       "      <td>0.896378</td>\n",
       "      <td>0.898462</td>\n",
       "      <td>0.894617</td>\n",
       "      <td>6187</td>\n",
       "      <td>4093</td>\n",
       "      <td>645</td>\n",
       "      <td>499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>Reg_Log_Binario</td>\n",
       "      <td>('stop_words', 'urls', 'norm_letters', 'prunin...</td>\n",
       "      <td>4155</td>\n",
       "      <td>0.885329</td>\n",
       "      <td>0.881429</td>\n",
       "      <td>0.883096</td>\n",
       "      <td>0.879989</td>\n",
       "      <td>6093</td>\n",
       "      <td>4021</td>\n",
       "      <td>717</td>\n",
       "      <td>593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>Reg_Log_Binario</td>\n",
       "      <td>('stop_words', 'urls', 'norm_letters', 'prunin...</td>\n",
       "      <td>7604</td>\n",
       "      <td>0.894695</td>\n",
       "      <td>0.891251</td>\n",
       "      <td>0.892375</td>\n",
       "      <td>0.890235</td>\n",
       "      <td>6127</td>\n",
       "      <td>4094</td>\n",
       "      <td>644</td>\n",
       "      <td>559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>Reg_Log_Binario</td>\n",
       "      <td>('stemming', 'urls', 'norm_letters', 'pruning10')</td>\n",
       "      <td>3569</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.903344</td>\n",
       "      <td>0.903768</td>\n",
       "      <td>0.902935</td>\n",
       "      <td>6167</td>\n",
       "      <td>4186</td>\n",
       "      <td>552</td>\n",
       "      <td>519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>Reg_Log_Binario</td>\n",
       "      <td>('stemming', 'urls', 'norm_letters', 'pruning5')</td>\n",
       "      <td>5709</td>\n",
       "      <td>0.908876</td>\n",
       "      <td>0.906063</td>\n",
       "      <td>0.906437</td>\n",
       "      <td>0.905701</td>\n",
       "      <td>6180</td>\n",
       "      <td>4203</td>\n",
       "      <td>535</td>\n",
       "      <td>506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>Reg_Log_Binario</td>\n",
       "      <td>('lemmatization', 'urls', 'norm_letters', 'pru...</td>\n",
       "      <td>3580</td>\n",
       "      <td>0.905287</td>\n",
       "      <td>0.902186</td>\n",
       "      <td>0.903356</td>\n",
       "      <td>0.901129</td>\n",
       "      <td>6188</td>\n",
       "      <td>4154</td>\n",
       "      <td>584</td>\n",
       "      <td>498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>Reg_Log_Binario</td>\n",
       "      <td>('lemmatization', 'urls', 'norm_letters', 'pru...</td>\n",
       "      <td>5974</td>\n",
       "      <td>0.908613</td>\n",
       "      <td>0.905682</td>\n",
       "      <td>0.906568</td>\n",
       "      <td>0.904862</td>\n",
       "      <td>6197</td>\n",
       "      <td>4183</td>\n",
       "      <td>555</td>\n",
       "      <td>489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>Reg_Log_Binario</td>\n",
       "      <td>('stop_words', 'stemming', 'urls', 'norm_lette...</td>\n",
       "      <td>3491</td>\n",
       "      <td>0.898284</td>\n",
       "      <td>0.894873</td>\n",
       "      <td>0.896380</td>\n",
       "      <td>0.893547</td>\n",
       "      <td>6160</td>\n",
       "      <td>4102</td>\n",
       "      <td>636</td>\n",
       "      <td>526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>Reg_Log_Binario</td>\n",
       "      <td>('stop_words', 'stemming', 'urls', 'norm_lette...</td>\n",
       "      <td>5629</td>\n",
       "      <td>0.902924</td>\n",
       "      <td>0.899736</td>\n",
       "      <td>0.900943</td>\n",
       "      <td>0.898648</td>\n",
       "      <td>6176</td>\n",
       "      <td>4139</td>\n",
       "      <td>599</td>\n",
       "      <td>510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>Reg_Log_Binario</td>\n",
       "      <td>('stop_words', 'lemmatization', 'urls', 'norm_...</td>\n",
       "      <td>3517</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.892233</td>\n",
       "      <td>0.894199</td>\n",
       "      <td>0.890562</td>\n",
       "      <td>6161</td>\n",
       "      <td>4073</td>\n",
       "      <td>665</td>\n",
       "      <td>525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>Reg_Log_Binario</td>\n",
       "      <td>('stop_words', 'lemmatization', 'urls', 'norm_...</td>\n",
       "      <td>5911</td>\n",
       "      <td>0.900385</td>\n",
       "      <td>0.896963</td>\n",
       "      <td>0.898855</td>\n",
       "      <td>0.895342</td>\n",
       "      <td>6184</td>\n",
       "      <td>4102</td>\n",
       "      <td>636</td>\n",
       "      <td>502</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>639 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  9                                                  10  \\\n",
       "0       Bayesiano_TF                                    ('stop_words',)   \n",
       "1       Bayesiano_TF                                      ('stemming',)   \n",
       "2       Bayesiano_TF                                 ('lemmatization',)   \n",
       "3       Bayesiano_TF                                          ('urls',)   \n",
       "4       Bayesiano_TF                                  ('norm_letters',)   \n",
       "5       Bayesiano_TF                                     ('pruning10',)   \n",
       "6       Bayesiano_TF                                      ('pruning5',)   \n",
       "7       Bayesiano_TF                         ('stop_words', 'stemming')   \n",
       "8       Bayesiano_TF                    ('stop_words', 'lemmatization')   \n",
       "9       Bayesiano_TF                             ('stop_words', 'urls')   \n",
       "10      Bayesiano_TF                     ('stop_words', 'norm_letters')   \n",
       "11      Bayesiano_TF                        ('stop_words', 'pruning10')   \n",
       "12      Bayesiano_TF                         ('stop_words', 'pruning5')   \n",
       "13      Bayesiano_TF                               ('stemming', 'urls')   \n",
       "14      Bayesiano_TF                       ('stemming', 'norm_letters')   \n",
       "15      Bayesiano_TF                          ('stemming', 'pruning10')   \n",
       "16      Bayesiano_TF                           ('stemming', 'pruning5')   \n",
       "17      Bayesiano_TF                          ('lemmatization', 'urls')   \n",
       "18      Bayesiano_TF                  ('lemmatization', 'norm_letters')   \n",
       "19      Bayesiano_TF                     ('lemmatization', 'pruning10')   \n",
       "20      Bayesiano_TF                      ('lemmatization', 'pruning5')   \n",
       "21      Bayesiano_TF                           ('urls', 'norm_letters')   \n",
       "22      Bayesiano_TF                              ('urls', 'pruning10')   \n",
       "23      Bayesiano_TF                               ('urls', 'pruning5')   \n",
       "24      Bayesiano_TF                      ('norm_letters', 'pruning10')   \n",
       "25      Bayesiano_TF                       ('norm_letters', 'pruning5')   \n",
       "26      Bayesiano_TF                 ('stop_words', 'stemming', 'urls')   \n",
       "27      Bayesiano_TF         ('stop_words', 'stemming', 'norm_letters')   \n",
       "28      Bayesiano_TF            ('stop_words', 'stemming', 'pruning10')   \n",
       "29      Bayesiano_TF             ('stop_words', 'stemming', 'pruning5')   \n",
       "..               ...                                                ...   \n",
       "609  Reg_Log_Binario                   ('stemming', 'urls', 'pruning5')   \n",
       "610  Reg_Log_Binario          ('stemming', 'norm_letters', 'pruning10')   \n",
       "611  Reg_Log_Binario           ('stemming', 'norm_letters', 'pruning5')   \n",
       "612  Reg_Log_Binario          ('lemmatization', 'urls', 'norm_letters')   \n",
       "613  Reg_Log_Binario             ('lemmatization', 'urls', 'pruning10')   \n",
       "614  Reg_Log_Binario              ('lemmatization', 'urls', 'pruning5')   \n",
       "615  Reg_Log_Binario     ('lemmatization', 'norm_letters', 'pruning10')   \n",
       "616  Reg_Log_Binario      ('lemmatization', 'norm_letters', 'pruning5')   \n",
       "617  Reg_Log_Binario              ('urls', 'norm_letters', 'pruning10')   \n",
       "618  Reg_Log_Binario               ('urls', 'norm_letters', 'pruning5')   \n",
       "619  Reg_Log_Binario  ('stop_words', 'stemming', 'urls', 'norm_lette...   \n",
       "620  Reg_Log_Binario    ('stop_words', 'stemming', 'urls', 'pruning10')   \n",
       "621  Reg_Log_Binario     ('stop_words', 'stemming', 'urls', 'pruning5')   \n",
       "622  Reg_Log_Binario  ('stop_words', 'stemming', 'norm_letters', 'pr...   \n",
       "623  Reg_Log_Binario  ('stop_words', 'stemming', 'norm_letters', 'pr...   \n",
       "624  Reg_Log_Binario  ('stop_words', 'lemmatization', 'urls', 'norm_...   \n",
       "625  Reg_Log_Binario  ('stop_words', 'lemmatization', 'urls', 'pruni...   \n",
       "626  Reg_Log_Binario  ('stop_words', 'lemmatization', 'urls', 'pruni...   \n",
       "627  Reg_Log_Binario  ('stop_words', 'lemmatization', 'norm_letters'...   \n",
       "628  Reg_Log_Binario  ('stop_words', 'lemmatization', 'norm_letters'...   \n",
       "629  Reg_Log_Binario  ('stop_words', 'urls', 'norm_letters', 'prunin...   \n",
       "630  Reg_Log_Binario  ('stop_words', 'urls', 'norm_letters', 'prunin...   \n",
       "631  Reg_Log_Binario  ('stemming', 'urls', 'norm_letters', 'pruning10')   \n",
       "632  Reg_Log_Binario   ('stemming', 'urls', 'norm_letters', 'pruning5')   \n",
       "633  Reg_Log_Binario  ('lemmatization', 'urls', 'norm_letters', 'pru...   \n",
       "634  Reg_Log_Binario  ('lemmatization', 'urls', 'norm_letters', 'pru...   \n",
       "635  Reg_Log_Binario  ('stop_words', 'stemming', 'urls', 'norm_lette...   \n",
       "636  Reg_Log_Binario  ('stop_words', 'stemming', 'urls', 'norm_lette...   \n",
       "637  Reg_Log_Binario  ('stop_words', 'lemmatization', 'urls', 'norm_...   \n",
       "638  Reg_Log_Binario  ('stop_words', 'lemmatization', 'urls', 'norm_...   \n",
       "\n",
       "        1         0         2         3         4     5     6    7    8   \n",
       "0    48099  0.868873  0.864606  0.865588  0.863716  5977  3949  789  709  \n",
       "1    32900  0.872286  0.869419  0.867375  0.872382  5829  4136  602  857  \n",
       "2    36795  0.873162  0.870209  0.868315  0.872822  5849  4126  612  837  \n",
       "3    40405  0.873687  0.870782  0.868830  0.873517  5847  4134  604  839  \n",
       "4    47550  0.874475  0.871272  0.869888  0.872960  5896  4094  644  790  \n",
       "5     4348  0.863708  0.861047  0.858698  0.865268  5724  4143  595  962  \n",
       "6     7822  0.868610  0.866004  0.863641  0.870133  5758  4165  573  928  \n",
       "7    32814  0.872024  0.868328  0.867958  0.868714  5938  4024  714  748  \n",
       "8    36731  0.871148  0.867427  0.867058  0.867812  5933  4019  719  753  \n",
       "9    40155  0.871236  0.867608  0.867007  0.868256  5922  4031  707  764  \n",
       "10   47300  0.869748  0.865475  0.866568  0.864494  5986  3950  788  700  \n",
       "11    4163  0.858368  0.854804  0.853401  0.856556  5798  4008  730  888  \n",
       "12    7615  0.863095  0.859642  0.858232  0.861394  5826  4034  704  860  \n",
       "13   24956  0.870886  0.868410  0.865979  0.872876  5758  4191  547  928  \n",
       "14   32097  0.872637  0.869749  0.867742  0.872620  5835  4134  604  851  \n",
       "15    3579  0.869660  0.867002  0.864685  0.870876  5775  4160  578  911  \n",
       "16    5712  0.870536  0.867876  0.865569  0.871686  5783  4162  576  903  \n",
       "17   28850  0.872899  0.870278  0.867962  0.874074  5798  4174  564  888  \n",
       "18   36091  0.872637  0.869679  0.867777  0.872312  5845  4124  614  841  \n",
       "19    3592  0.869048  0.866326  0.864058  0.870015  5779  4149  589  907  \n",
       "20    6002  0.870798  0.868133  0.865834  0.871910  5786  4162  576  900  \n",
       "21   39606  0.874125  0.871212  0.869285  0.873891  5852  4134  604  834  \n",
       "22    4337  0.863708  0.861195  0.858790  0.865945  5702  4165  573  984  \n",
       "23    7812  0.868610  0.866104  0.863685  0.870594  5743  4180  558  943  \n",
       "24    4349  0.863445  0.860817  0.858452  0.865167  5717  4147  591  969  \n",
       "25    7822  0.868697  0.866117  0.863738  0.870330  5755  4169  569  931  \n",
       "26   24870  0.870886  0.867662  0.866155  0.869556  5866  4083  655  820  \n",
       "27   32012  0.871324  0.867575  0.867290  0.867870  5938  4016  722  748  \n",
       "28    3500  0.864758  0.861490  0.859828  0.863675  5817  4062  676  869  \n",
       "29    5631  0.868172  0.865063  0.863259  0.867514  5826  4092  646  860  \n",
       "..     ...       ...       ...       ...       ...   ...   ...  ...  ...  \n",
       "609   5701  0.907563  0.904658  0.905261  0.904088  6181  4187  551  505  \n",
       "610   3578  0.905287  0.902317  0.902889  0.901774  6167  4175  563  519  \n",
       "611   5722  0.907213  0.904309  0.904857  0.903788  6177  4187  551  509  \n",
       "612  28146  0.909664  0.906706  0.907889  0.905636  6213  4179  559  473  \n",
       "613   3582  0.905200  0.902074  0.903348  0.900931  6191  4150  588  495  \n",
       "614   5991  0.908263  0.905296  0.906298  0.904378  6199  4177  561  487  \n",
       "615   3589  0.905375  0.902267  0.903482  0.901173  6190  4153  585  496  \n",
       "616   5987  0.908001  0.905034  0.905991  0.904154  6196  4177  561  490  \n",
       "617   4339  0.895571  0.892286  0.892884  0.891721  6113  4118  620  573  \n",
       "618   7810  0.902574  0.899515  0.900097  0.898964  6152  4159  579  534  \n",
       "619  24069  0.902836  0.899557  0.901175  0.898143  6189  4125  613  497  \n",
       "620   3490  0.898897  0.895503  0.897027  0.894163  6164  4105  633  522  \n",
       "621   5620  0.902486  0.899287  0.900478  0.898213  6173  4137  601  513  \n",
       "622   3500  0.898985  0.895610  0.897059  0.894330  6162  4108  630  524  \n",
       "623   5642  0.903536  0.900385  0.901520  0.899356  6177  4145  593  509  \n",
       "624  28081  0.902223  0.898827  0.900907  0.897066  6200  4107  631  486  \n",
       "625   3520  0.895833  0.892240  0.894174  0.890592  6160  4074  664  526  \n",
       "626   5929  0.899947  0.896514  0.898387  0.894907  6181  4100  638  505  \n",
       "627   3526  0.893645  0.889907  0.892137  0.888046  6157  4052  686  529  \n",
       "628   5924  0.899860  0.896378  0.898462  0.894617  6187  4093  645  499  \n",
       "629   4155  0.885329  0.881429  0.883096  0.879989  6093  4021  717  593  \n",
       "630   7604  0.894695  0.891251  0.892375  0.890235  6127  4094  644  559  \n",
       "631   3569  0.906250  0.903344  0.903768  0.902935  6167  4186  552  519  \n",
       "632   5709  0.908876  0.906063  0.906437  0.905701  6180  4203  535  506  \n",
       "633   3580  0.905287  0.902186  0.903356  0.901129  6188  4154  584  498  \n",
       "634   5974  0.908613  0.905682  0.906568  0.904862  6197  4183  555  489  \n",
       "635   3491  0.898284  0.894873  0.896380  0.893547  6160  4102  636  526  \n",
       "636   5629  0.902924  0.899736  0.900943  0.898648  6176  4139  599  510  \n",
       "637   3517  0.895833  0.892233  0.894199  0.890562  6161  4073  665  525  \n",
       "638   5911  0.900385  0.896963  0.898855  0.895342  6184  4102  636  502  \n",
       "\n",
       "[639 rows x 11 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.columns = ['clf_name','comb','features_number','accuracy','f1_score','precision','recall','true_positives','true_negatives','false_positives','false_negatives']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clf_name</th>\n",
       "      <th>comb</th>\n",
       "      <th>features_number</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>true_positives</th>\n",
       "      <th>true_negatives</th>\n",
       "      <th>false_positives</th>\n",
       "      <th>false_negatives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bayesiano_TF</td>\n",
       "      <td>('stop_words',)</td>\n",
       "      <td>48099</td>\n",
       "      <td>0.868873</td>\n",
       "      <td>0.864606</td>\n",
       "      <td>0.865588</td>\n",
       "      <td>0.863716</td>\n",
       "      <td>5977</td>\n",
       "      <td>3949</td>\n",
       "      <td>789</td>\n",
       "      <td>709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bayesiano_TF</td>\n",
       "      <td>('stemming',)</td>\n",
       "      <td>32900</td>\n",
       "      <td>0.872286</td>\n",
       "      <td>0.869419</td>\n",
       "      <td>0.867375</td>\n",
       "      <td>0.872382</td>\n",
       "      <td>5829</td>\n",
       "      <td>4136</td>\n",
       "      <td>602</td>\n",
       "      <td>857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bayesiano_TF</td>\n",
       "      <td>('lemmatization',)</td>\n",
       "      <td>36795</td>\n",
       "      <td>0.873162</td>\n",
       "      <td>0.870209</td>\n",
       "      <td>0.868315</td>\n",
       "      <td>0.872822</td>\n",
       "      <td>5849</td>\n",
       "      <td>4126</td>\n",
       "      <td>612</td>\n",
       "      <td>837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bayesiano_TF</td>\n",
       "      <td>('urls',)</td>\n",
       "      <td>40405</td>\n",
       "      <td>0.873687</td>\n",
       "      <td>0.870782</td>\n",
       "      <td>0.868830</td>\n",
       "      <td>0.873517</td>\n",
       "      <td>5847</td>\n",
       "      <td>4134</td>\n",
       "      <td>604</td>\n",
       "      <td>839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bayesiano_TF</td>\n",
       "      <td>('norm_letters',)</td>\n",
       "      <td>47550</td>\n",
       "      <td>0.874475</td>\n",
       "      <td>0.871272</td>\n",
       "      <td>0.869888</td>\n",
       "      <td>0.872960</td>\n",
       "      <td>5896</td>\n",
       "      <td>4094</td>\n",
       "      <td>644</td>\n",
       "      <td>790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bayesiano_TF</td>\n",
       "      <td>('pruning10',)</td>\n",
       "      <td>4348</td>\n",
       "      <td>0.863708</td>\n",
       "      <td>0.861047</td>\n",
       "      <td>0.858698</td>\n",
       "      <td>0.865268</td>\n",
       "      <td>5724</td>\n",
       "      <td>4143</td>\n",
       "      <td>595</td>\n",
       "      <td>962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bayesiano_TF</td>\n",
       "      <td>('pruning5',)</td>\n",
       "      <td>7822</td>\n",
       "      <td>0.868610</td>\n",
       "      <td>0.866004</td>\n",
       "      <td>0.863641</td>\n",
       "      <td>0.870133</td>\n",
       "      <td>5758</td>\n",
       "      <td>4165</td>\n",
       "      <td>573</td>\n",
       "      <td>928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Bayesiano_TF</td>\n",
       "      <td>('stop_words', 'stemming')</td>\n",
       "      <td>32814</td>\n",
       "      <td>0.872024</td>\n",
       "      <td>0.868328</td>\n",
       "      <td>0.867958</td>\n",
       "      <td>0.868714</td>\n",
       "      <td>5938</td>\n",
       "      <td>4024</td>\n",
       "      <td>714</td>\n",
       "      <td>748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Bayesiano_TF</td>\n",
       "      <td>('stop_words', 'lemmatization')</td>\n",
       "      <td>36731</td>\n",
       "      <td>0.871148</td>\n",
       "      <td>0.867427</td>\n",
       "      <td>0.867058</td>\n",
       "      <td>0.867812</td>\n",
       "      <td>5933</td>\n",
       "      <td>4019</td>\n",
       "      <td>719</td>\n",
       "      <td>753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Bayesiano_TF</td>\n",
       "      <td>('stop_words', 'urls')</td>\n",
       "      <td>40155</td>\n",
       "      <td>0.871236</td>\n",
       "      <td>0.867608</td>\n",
       "      <td>0.867007</td>\n",
       "      <td>0.868256</td>\n",
       "      <td>5922</td>\n",
       "      <td>4031</td>\n",
       "      <td>707</td>\n",
       "      <td>764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Bayesiano_TF</td>\n",
       "      <td>('stop_words', 'norm_letters')</td>\n",
       "      <td>47300</td>\n",
       "      <td>0.869748</td>\n",
       "      <td>0.865475</td>\n",
       "      <td>0.866568</td>\n",
       "      <td>0.864494</td>\n",
       "      <td>5986</td>\n",
       "      <td>3950</td>\n",
       "      <td>788</td>\n",
       "      <td>700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Bayesiano_TF</td>\n",
       "      <td>('stop_words', 'pruning10')</td>\n",
       "      <td>4163</td>\n",
       "      <td>0.858368</td>\n",
       "      <td>0.854804</td>\n",
       "      <td>0.853401</td>\n",
       "      <td>0.856556</td>\n",
       "      <td>5798</td>\n",
       "      <td>4008</td>\n",
       "      <td>730</td>\n",
       "      <td>888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Bayesiano_TF</td>\n",
       "      <td>('stop_words', 'pruning5')</td>\n",
       "      <td>7615</td>\n",
       "      <td>0.863095</td>\n",
       "      <td>0.859642</td>\n",
       "      <td>0.858232</td>\n",
       "      <td>0.861394</td>\n",
       "      <td>5826</td>\n",
       "      <td>4034</td>\n",
       "      <td>704</td>\n",
       "      <td>860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Bayesiano_TF</td>\n",
       "      <td>('stemming', 'urls')</td>\n",
       "      <td>24956</td>\n",
       "      <td>0.870886</td>\n",
       "      <td>0.868410</td>\n",
       "      <td>0.865979</td>\n",
       "      <td>0.872876</td>\n",
       "      <td>5758</td>\n",
       "      <td>4191</td>\n",
       "      <td>547</td>\n",
       "      <td>928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Bayesiano_TF</td>\n",
       "      <td>('stemming', 'norm_letters')</td>\n",
       "      <td>32097</td>\n",
       "      <td>0.872637</td>\n",
       "      <td>0.869749</td>\n",
       "      <td>0.867742</td>\n",
       "      <td>0.872620</td>\n",
       "      <td>5835</td>\n",
       "      <td>4134</td>\n",
       "      <td>604</td>\n",
       "      <td>851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Bayesiano_TF</td>\n",
       "      <td>('stemming', 'pruning10')</td>\n",
       "      <td>3579</td>\n",
       "      <td>0.869660</td>\n",
       "      <td>0.867002</td>\n",
       "      <td>0.864685</td>\n",
       "      <td>0.870876</td>\n",
       "      <td>5775</td>\n",
       "      <td>4160</td>\n",
       "      <td>578</td>\n",
       "      <td>911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Bayesiano_TF</td>\n",
       "      <td>('stemming', 'pruning5')</td>\n",
       "      <td>5712</td>\n",
       "      <td>0.870536</td>\n",
       "      <td>0.867876</td>\n",
       "      <td>0.865569</td>\n",
       "      <td>0.871686</td>\n",
       "      <td>5783</td>\n",
       "      <td>4162</td>\n",
       "      <td>576</td>\n",
       "      <td>903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Bayesiano_TF</td>\n",
       "      <td>('lemmatization', 'urls')</td>\n",
       "      <td>28850</td>\n",
       "      <td>0.872899</td>\n",
       "      <td>0.870278</td>\n",
       "      <td>0.867962</td>\n",
       "      <td>0.874074</td>\n",
       "      <td>5798</td>\n",
       "      <td>4174</td>\n",
       "      <td>564</td>\n",
       "      <td>888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Bayesiano_TF</td>\n",
       "      <td>('lemmatization', 'norm_letters')</td>\n",
       "      <td>36091</td>\n",
       "      <td>0.872637</td>\n",
       "      <td>0.869679</td>\n",
       "      <td>0.867777</td>\n",
       "      <td>0.872312</td>\n",
       "      <td>5845</td>\n",
       "      <td>4124</td>\n",
       "      <td>614</td>\n",
       "      <td>841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Bayesiano_TF</td>\n",
       "      <td>('lemmatization', 'pruning10')</td>\n",
       "      <td>3592</td>\n",
       "      <td>0.869048</td>\n",
       "      <td>0.866326</td>\n",
       "      <td>0.864058</td>\n",
       "      <td>0.870015</td>\n",
       "      <td>5779</td>\n",
       "      <td>4149</td>\n",
       "      <td>589</td>\n",
       "      <td>907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Bayesiano_TF</td>\n",
       "      <td>('lemmatization', 'pruning5')</td>\n",
       "      <td>6002</td>\n",
       "      <td>0.870798</td>\n",
       "      <td>0.868133</td>\n",
       "      <td>0.865834</td>\n",
       "      <td>0.871910</td>\n",
       "      <td>5786</td>\n",
       "      <td>4162</td>\n",
       "      <td>576</td>\n",
       "      <td>900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Bayesiano_TF</td>\n",
       "      <td>('urls', 'norm_letters')</td>\n",
       "      <td>39606</td>\n",
       "      <td>0.874125</td>\n",
       "      <td>0.871212</td>\n",
       "      <td>0.869285</td>\n",
       "      <td>0.873891</td>\n",
       "      <td>5852</td>\n",
       "      <td>4134</td>\n",
       "      <td>604</td>\n",
       "      <td>834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Bayesiano_TF</td>\n",
       "      <td>('urls', 'pruning10')</td>\n",
       "      <td>4337</td>\n",
       "      <td>0.863708</td>\n",
       "      <td>0.861195</td>\n",
       "      <td>0.858790</td>\n",
       "      <td>0.865945</td>\n",
       "      <td>5702</td>\n",
       "      <td>4165</td>\n",
       "      <td>573</td>\n",
       "      <td>984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Bayesiano_TF</td>\n",
       "      <td>('urls', 'pruning5')</td>\n",
       "      <td>7812</td>\n",
       "      <td>0.868610</td>\n",
       "      <td>0.866104</td>\n",
       "      <td>0.863685</td>\n",
       "      <td>0.870594</td>\n",
       "      <td>5743</td>\n",
       "      <td>4180</td>\n",
       "      <td>558</td>\n",
       "      <td>943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Bayesiano_TF</td>\n",
       "      <td>('norm_letters', 'pruning10')</td>\n",
       "      <td>4349</td>\n",
       "      <td>0.863445</td>\n",
       "      <td>0.860817</td>\n",
       "      <td>0.858452</td>\n",
       "      <td>0.865167</td>\n",
       "      <td>5717</td>\n",
       "      <td>4147</td>\n",
       "      <td>591</td>\n",
       "      <td>969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Bayesiano_TF</td>\n",
       "      <td>('norm_letters', 'pruning5')</td>\n",
       "      <td>7822</td>\n",
       "      <td>0.868697</td>\n",
       "      <td>0.866117</td>\n",
       "      <td>0.863738</td>\n",
       "      <td>0.870330</td>\n",
       "      <td>5755</td>\n",
       "      <td>4169</td>\n",
       "      <td>569</td>\n",
       "      <td>931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Bayesiano_TF</td>\n",
       "      <td>('stop_words', 'stemming', 'urls')</td>\n",
       "      <td>24870</td>\n",
       "      <td>0.870886</td>\n",
       "      <td>0.867662</td>\n",
       "      <td>0.866155</td>\n",
       "      <td>0.869556</td>\n",
       "      <td>5866</td>\n",
       "      <td>4083</td>\n",
       "      <td>655</td>\n",
       "      <td>820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Bayesiano_TF</td>\n",
       "      <td>('stop_words', 'stemming', 'norm_letters')</td>\n",
       "      <td>32012</td>\n",
       "      <td>0.871324</td>\n",
       "      <td>0.867575</td>\n",
       "      <td>0.867290</td>\n",
       "      <td>0.867870</td>\n",
       "      <td>5938</td>\n",
       "      <td>4016</td>\n",
       "      <td>722</td>\n",
       "      <td>748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Bayesiano_TF</td>\n",
       "      <td>('stop_words', 'stemming', 'pruning10')</td>\n",
       "      <td>3500</td>\n",
       "      <td>0.864758</td>\n",
       "      <td>0.861490</td>\n",
       "      <td>0.859828</td>\n",
       "      <td>0.863675</td>\n",
       "      <td>5817</td>\n",
       "      <td>4062</td>\n",
       "      <td>676</td>\n",
       "      <td>869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Bayesiano_TF</td>\n",
       "      <td>('stop_words', 'stemming', 'pruning5')</td>\n",
       "      <td>5631</td>\n",
       "      <td>0.868172</td>\n",
       "      <td>0.865063</td>\n",
       "      <td>0.863259</td>\n",
       "      <td>0.867514</td>\n",
       "      <td>5826</td>\n",
       "      <td>4092</td>\n",
       "      <td>646</td>\n",
       "      <td>860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>Reg_Log_Binario</td>\n",
       "      <td>('stemming', 'urls', 'pruning5')</td>\n",
       "      <td>5701</td>\n",
       "      <td>0.907563</td>\n",
       "      <td>0.904658</td>\n",
       "      <td>0.905261</td>\n",
       "      <td>0.904088</td>\n",
       "      <td>6181</td>\n",
       "      <td>4187</td>\n",
       "      <td>551</td>\n",
       "      <td>505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>Reg_Log_Binario</td>\n",
       "      <td>('stemming', 'norm_letters', 'pruning10')</td>\n",
       "      <td>3578</td>\n",
       "      <td>0.905287</td>\n",
       "      <td>0.902317</td>\n",
       "      <td>0.902889</td>\n",
       "      <td>0.901774</td>\n",
       "      <td>6167</td>\n",
       "      <td>4175</td>\n",
       "      <td>563</td>\n",
       "      <td>519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>Reg_Log_Binario</td>\n",
       "      <td>('stemming', 'norm_letters', 'pruning5')</td>\n",
       "      <td>5722</td>\n",
       "      <td>0.907213</td>\n",
       "      <td>0.904309</td>\n",
       "      <td>0.904857</td>\n",
       "      <td>0.903788</td>\n",
       "      <td>6177</td>\n",
       "      <td>4187</td>\n",
       "      <td>551</td>\n",
       "      <td>509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>Reg_Log_Binario</td>\n",
       "      <td>('lemmatization', 'urls', 'norm_letters')</td>\n",
       "      <td>28146</td>\n",
       "      <td>0.909664</td>\n",
       "      <td>0.906706</td>\n",
       "      <td>0.907889</td>\n",
       "      <td>0.905636</td>\n",
       "      <td>6213</td>\n",
       "      <td>4179</td>\n",
       "      <td>559</td>\n",
       "      <td>473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>Reg_Log_Binario</td>\n",
       "      <td>('lemmatization', 'urls', 'pruning10')</td>\n",
       "      <td>3582</td>\n",
       "      <td>0.905200</td>\n",
       "      <td>0.902074</td>\n",
       "      <td>0.903348</td>\n",
       "      <td>0.900931</td>\n",
       "      <td>6191</td>\n",
       "      <td>4150</td>\n",
       "      <td>588</td>\n",
       "      <td>495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>Reg_Log_Binario</td>\n",
       "      <td>('lemmatization', 'urls', 'pruning5')</td>\n",
       "      <td>5991</td>\n",
       "      <td>0.908263</td>\n",
       "      <td>0.905296</td>\n",
       "      <td>0.906298</td>\n",
       "      <td>0.904378</td>\n",
       "      <td>6199</td>\n",
       "      <td>4177</td>\n",
       "      <td>561</td>\n",
       "      <td>487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>Reg_Log_Binario</td>\n",
       "      <td>('lemmatization', 'norm_letters', 'pruning10')</td>\n",
       "      <td>3589</td>\n",
       "      <td>0.905375</td>\n",
       "      <td>0.902267</td>\n",
       "      <td>0.903482</td>\n",
       "      <td>0.901173</td>\n",
       "      <td>6190</td>\n",
       "      <td>4153</td>\n",
       "      <td>585</td>\n",
       "      <td>496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>Reg_Log_Binario</td>\n",
       "      <td>('lemmatization', 'norm_letters', 'pruning5')</td>\n",
       "      <td>5987</td>\n",
       "      <td>0.908001</td>\n",
       "      <td>0.905034</td>\n",
       "      <td>0.905991</td>\n",
       "      <td>0.904154</td>\n",
       "      <td>6196</td>\n",
       "      <td>4177</td>\n",
       "      <td>561</td>\n",
       "      <td>490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>Reg_Log_Binario</td>\n",
       "      <td>('urls', 'norm_letters', 'pruning10')</td>\n",
       "      <td>4339</td>\n",
       "      <td>0.895571</td>\n",
       "      <td>0.892286</td>\n",
       "      <td>0.892884</td>\n",
       "      <td>0.891721</td>\n",
       "      <td>6113</td>\n",
       "      <td>4118</td>\n",
       "      <td>620</td>\n",
       "      <td>573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>Reg_Log_Binario</td>\n",
       "      <td>('urls', 'norm_letters', 'pruning5')</td>\n",
       "      <td>7810</td>\n",
       "      <td>0.902574</td>\n",
       "      <td>0.899515</td>\n",
       "      <td>0.900097</td>\n",
       "      <td>0.898964</td>\n",
       "      <td>6152</td>\n",
       "      <td>4159</td>\n",
       "      <td>579</td>\n",
       "      <td>534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>Reg_Log_Binario</td>\n",
       "      <td>('stop_words', 'stemming', 'urls', 'norm_lette...</td>\n",
       "      <td>24069</td>\n",
       "      <td>0.902836</td>\n",
       "      <td>0.899557</td>\n",
       "      <td>0.901175</td>\n",
       "      <td>0.898143</td>\n",
       "      <td>6189</td>\n",
       "      <td>4125</td>\n",
       "      <td>613</td>\n",
       "      <td>497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>Reg_Log_Binario</td>\n",
       "      <td>('stop_words', 'stemming', 'urls', 'pruning10')</td>\n",
       "      <td>3490</td>\n",
       "      <td>0.898897</td>\n",
       "      <td>0.895503</td>\n",
       "      <td>0.897027</td>\n",
       "      <td>0.894163</td>\n",
       "      <td>6164</td>\n",
       "      <td>4105</td>\n",
       "      <td>633</td>\n",
       "      <td>522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>Reg_Log_Binario</td>\n",
       "      <td>('stop_words', 'stemming', 'urls', 'pruning5')</td>\n",
       "      <td>5620</td>\n",
       "      <td>0.902486</td>\n",
       "      <td>0.899287</td>\n",
       "      <td>0.900478</td>\n",
       "      <td>0.898213</td>\n",
       "      <td>6173</td>\n",
       "      <td>4137</td>\n",
       "      <td>601</td>\n",
       "      <td>513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>Reg_Log_Binario</td>\n",
       "      <td>('stop_words', 'stemming', 'norm_letters', 'pr...</td>\n",
       "      <td>3500</td>\n",
       "      <td>0.898985</td>\n",
       "      <td>0.895610</td>\n",
       "      <td>0.897059</td>\n",
       "      <td>0.894330</td>\n",
       "      <td>6162</td>\n",
       "      <td>4108</td>\n",
       "      <td>630</td>\n",
       "      <td>524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>Reg_Log_Binario</td>\n",
       "      <td>('stop_words', 'stemming', 'norm_letters', 'pr...</td>\n",
       "      <td>5642</td>\n",
       "      <td>0.903536</td>\n",
       "      <td>0.900385</td>\n",
       "      <td>0.901520</td>\n",
       "      <td>0.899356</td>\n",
       "      <td>6177</td>\n",
       "      <td>4145</td>\n",
       "      <td>593</td>\n",
       "      <td>509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>Reg_Log_Binario</td>\n",
       "      <td>('stop_words', 'lemmatization', 'urls', 'norm_...</td>\n",
       "      <td>28081</td>\n",
       "      <td>0.902223</td>\n",
       "      <td>0.898827</td>\n",
       "      <td>0.900907</td>\n",
       "      <td>0.897066</td>\n",
       "      <td>6200</td>\n",
       "      <td>4107</td>\n",
       "      <td>631</td>\n",
       "      <td>486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>Reg_Log_Binario</td>\n",
       "      <td>('stop_words', 'lemmatization', 'urls', 'pruni...</td>\n",
       "      <td>3520</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.892240</td>\n",
       "      <td>0.894174</td>\n",
       "      <td>0.890592</td>\n",
       "      <td>6160</td>\n",
       "      <td>4074</td>\n",
       "      <td>664</td>\n",
       "      <td>526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>Reg_Log_Binario</td>\n",
       "      <td>('stop_words', 'lemmatization', 'urls', 'pruni...</td>\n",
       "      <td>5929</td>\n",
       "      <td>0.899947</td>\n",
       "      <td>0.896514</td>\n",
       "      <td>0.898387</td>\n",
       "      <td>0.894907</td>\n",
       "      <td>6181</td>\n",
       "      <td>4100</td>\n",
       "      <td>638</td>\n",
       "      <td>505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>Reg_Log_Binario</td>\n",
       "      <td>('stop_words', 'lemmatization', 'norm_letters'...</td>\n",
       "      <td>3526</td>\n",
       "      <td>0.893645</td>\n",
       "      <td>0.889907</td>\n",
       "      <td>0.892137</td>\n",
       "      <td>0.888046</td>\n",
       "      <td>6157</td>\n",
       "      <td>4052</td>\n",
       "      <td>686</td>\n",
       "      <td>529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>Reg_Log_Binario</td>\n",
       "      <td>('stop_words', 'lemmatization', 'norm_letters'...</td>\n",
       "      <td>5924</td>\n",
       "      <td>0.899860</td>\n",
       "      <td>0.896378</td>\n",
       "      <td>0.898462</td>\n",
       "      <td>0.894617</td>\n",
       "      <td>6187</td>\n",
       "      <td>4093</td>\n",
       "      <td>645</td>\n",
       "      <td>499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>Reg_Log_Binario</td>\n",
       "      <td>('stop_words', 'urls', 'norm_letters', 'prunin...</td>\n",
       "      <td>4155</td>\n",
       "      <td>0.885329</td>\n",
       "      <td>0.881429</td>\n",
       "      <td>0.883096</td>\n",
       "      <td>0.879989</td>\n",
       "      <td>6093</td>\n",
       "      <td>4021</td>\n",
       "      <td>717</td>\n",
       "      <td>593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>Reg_Log_Binario</td>\n",
       "      <td>('stop_words', 'urls', 'norm_letters', 'prunin...</td>\n",
       "      <td>7604</td>\n",
       "      <td>0.894695</td>\n",
       "      <td>0.891251</td>\n",
       "      <td>0.892375</td>\n",
       "      <td>0.890235</td>\n",
       "      <td>6127</td>\n",
       "      <td>4094</td>\n",
       "      <td>644</td>\n",
       "      <td>559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>Reg_Log_Binario</td>\n",
       "      <td>('stemming', 'urls', 'norm_letters', 'pruning10')</td>\n",
       "      <td>3569</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.903344</td>\n",
       "      <td>0.903768</td>\n",
       "      <td>0.902935</td>\n",
       "      <td>6167</td>\n",
       "      <td>4186</td>\n",
       "      <td>552</td>\n",
       "      <td>519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>Reg_Log_Binario</td>\n",
       "      <td>('stemming', 'urls', 'norm_letters', 'pruning5')</td>\n",
       "      <td>5709</td>\n",
       "      <td>0.908876</td>\n",
       "      <td>0.906063</td>\n",
       "      <td>0.906437</td>\n",
       "      <td>0.905701</td>\n",
       "      <td>6180</td>\n",
       "      <td>4203</td>\n",
       "      <td>535</td>\n",
       "      <td>506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>Reg_Log_Binario</td>\n",
       "      <td>('lemmatization', 'urls', 'norm_letters', 'pru...</td>\n",
       "      <td>3580</td>\n",
       "      <td>0.905287</td>\n",
       "      <td>0.902186</td>\n",
       "      <td>0.903356</td>\n",
       "      <td>0.901129</td>\n",
       "      <td>6188</td>\n",
       "      <td>4154</td>\n",
       "      <td>584</td>\n",
       "      <td>498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>Reg_Log_Binario</td>\n",
       "      <td>('lemmatization', 'urls', 'norm_letters', 'pru...</td>\n",
       "      <td>5974</td>\n",
       "      <td>0.908613</td>\n",
       "      <td>0.905682</td>\n",
       "      <td>0.906568</td>\n",
       "      <td>0.904862</td>\n",
       "      <td>6197</td>\n",
       "      <td>4183</td>\n",
       "      <td>555</td>\n",
       "      <td>489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>Reg_Log_Binario</td>\n",
       "      <td>('stop_words', 'stemming', 'urls', 'norm_lette...</td>\n",
       "      <td>3491</td>\n",
       "      <td>0.898284</td>\n",
       "      <td>0.894873</td>\n",
       "      <td>0.896380</td>\n",
       "      <td>0.893547</td>\n",
       "      <td>6160</td>\n",
       "      <td>4102</td>\n",
       "      <td>636</td>\n",
       "      <td>526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>Reg_Log_Binario</td>\n",
       "      <td>('stop_words', 'stemming', 'urls', 'norm_lette...</td>\n",
       "      <td>5629</td>\n",
       "      <td>0.902924</td>\n",
       "      <td>0.899736</td>\n",
       "      <td>0.900943</td>\n",
       "      <td>0.898648</td>\n",
       "      <td>6176</td>\n",
       "      <td>4139</td>\n",
       "      <td>599</td>\n",
       "      <td>510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>Reg_Log_Binario</td>\n",
       "      <td>('stop_words', 'lemmatization', 'urls', 'norm_...</td>\n",
       "      <td>3517</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.892233</td>\n",
       "      <td>0.894199</td>\n",
       "      <td>0.890562</td>\n",
       "      <td>6161</td>\n",
       "      <td>4073</td>\n",
       "      <td>665</td>\n",
       "      <td>525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>Reg_Log_Binario</td>\n",
       "      <td>('stop_words', 'lemmatization', 'urls', 'norm_...</td>\n",
       "      <td>5911</td>\n",
       "      <td>0.900385</td>\n",
       "      <td>0.896963</td>\n",
       "      <td>0.898855</td>\n",
       "      <td>0.895342</td>\n",
       "      <td>6184</td>\n",
       "      <td>4102</td>\n",
       "      <td>636</td>\n",
       "      <td>502</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>639 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            clf_name                                               comb  \\\n",
       "0       Bayesiano_TF                                    ('stop_words',)   \n",
       "1       Bayesiano_TF                                      ('stemming',)   \n",
       "2       Bayesiano_TF                                 ('lemmatization',)   \n",
       "3       Bayesiano_TF                                          ('urls',)   \n",
       "4       Bayesiano_TF                                  ('norm_letters',)   \n",
       "5       Bayesiano_TF                                     ('pruning10',)   \n",
       "6       Bayesiano_TF                                      ('pruning5',)   \n",
       "7       Bayesiano_TF                         ('stop_words', 'stemming')   \n",
       "8       Bayesiano_TF                    ('stop_words', 'lemmatization')   \n",
       "9       Bayesiano_TF                             ('stop_words', 'urls')   \n",
       "10      Bayesiano_TF                     ('stop_words', 'norm_letters')   \n",
       "11      Bayesiano_TF                        ('stop_words', 'pruning10')   \n",
       "12      Bayesiano_TF                         ('stop_words', 'pruning5')   \n",
       "13      Bayesiano_TF                               ('stemming', 'urls')   \n",
       "14      Bayesiano_TF                       ('stemming', 'norm_letters')   \n",
       "15      Bayesiano_TF                          ('stemming', 'pruning10')   \n",
       "16      Bayesiano_TF                           ('stemming', 'pruning5')   \n",
       "17      Bayesiano_TF                          ('lemmatization', 'urls')   \n",
       "18      Bayesiano_TF                  ('lemmatization', 'norm_letters')   \n",
       "19      Bayesiano_TF                     ('lemmatization', 'pruning10')   \n",
       "20      Bayesiano_TF                      ('lemmatization', 'pruning5')   \n",
       "21      Bayesiano_TF                           ('urls', 'norm_letters')   \n",
       "22      Bayesiano_TF                              ('urls', 'pruning10')   \n",
       "23      Bayesiano_TF                               ('urls', 'pruning5')   \n",
       "24      Bayesiano_TF                      ('norm_letters', 'pruning10')   \n",
       "25      Bayesiano_TF                       ('norm_letters', 'pruning5')   \n",
       "26      Bayesiano_TF                 ('stop_words', 'stemming', 'urls')   \n",
       "27      Bayesiano_TF         ('stop_words', 'stemming', 'norm_letters')   \n",
       "28      Bayesiano_TF            ('stop_words', 'stemming', 'pruning10')   \n",
       "29      Bayesiano_TF             ('stop_words', 'stemming', 'pruning5')   \n",
       "..               ...                                                ...   \n",
       "609  Reg_Log_Binario                   ('stemming', 'urls', 'pruning5')   \n",
       "610  Reg_Log_Binario          ('stemming', 'norm_letters', 'pruning10')   \n",
       "611  Reg_Log_Binario           ('stemming', 'norm_letters', 'pruning5')   \n",
       "612  Reg_Log_Binario          ('lemmatization', 'urls', 'norm_letters')   \n",
       "613  Reg_Log_Binario             ('lemmatization', 'urls', 'pruning10')   \n",
       "614  Reg_Log_Binario              ('lemmatization', 'urls', 'pruning5')   \n",
       "615  Reg_Log_Binario     ('lemmatization', 'norm_letters', 'pruning10')   \n",
       "616  Reg_Log_Binario      ('lemmatization', 'norm_letters', 'pruning5')   \n",
       "617  Reg_Log_Binario              ('urls', 'norm_letters', 'pruning10')   \n",
       "618  Reg_Log_Binario               ('urls', 'norm_letters', 'pruning5')   \n",
       "619  Reg_Log_Binario  ('stop_words', 'stemming', 'urls', 'norm_lette...   \n",
       "620  Reg_Log_Binario    ('stop_words', 'stemming', 'urls', 'pruning10')   \n",
       "621  Reg_Log_Binario     ('stop_words', 'stemming', 'urls', 'pruning5')   \n",
       "622  Reg_Log_Binario  ('stop_words', 'stemming', 'norm_letters', 'pr...   \n",
       "623  Reg_Log_Binario  ('stop_words', 'stemming', 'norm_letters', 'pr...   \n",
       "624  Reg_Log_Binario  ('stop_words', 'lemmatization', 'urls', 'norm_...   \n",
       "625  Reg_Log_Binario  ('stop_words', 'lemmatization', 'urls', 'pruni...   \n",
       "626  Reg_Log_Binario  ('stop_words', 'lemmatization', 'urls', 'pruni...   \n",
       "627  Reg_Log_Binario  ('stop_words', 'lemmatization', 'norm_letters'...   \n",
       "628  Reg_Log_Binario  ('stop_words', 'lemmatization', 'norm_letters'...   \n",
       "629  Reg_Log_Binario  ('stop_words', 'urls', 'norm_letters', 'prunin...   \n",
       "630  Reg_Log_Binario  ('stop_words', 'urls', 'norm_letters', 'prunin...   \n",
       "631  Reg_Log_Binario  ('stemming', 'urls', 'norm_letters', 'pruning10')   \n",
       "632  Reg_Log_Binario   ('stemming', 'urls', 'norm_letters', 'pruning5')   \n",
       "633  Reg_Log_Binario  ('lemmatization', 'urls', 'norm_letters', 'pru...   \n",
       "634  Reg_Log_Binario  ('lemmatization', 'urls', 'norm_letters', 'pru...   \n",
       "635  Reg_Log_Binario  ('stop_words', 'stemming', 'urls', 'norm_lette...   \n",
       "636  Reg_Log_Binario  ('stop_words', 'stemming', 'urls', 'norm_lette...   \n",
       "637  Reg_Log_Binario  ('stop_words', 'lemmatization', 'urls', 'norm_...   \n",
       "638  Reg_Log_Binario  ('stop_words', 'lemmatization', 'urls', 'norm_...   \n",
       "\n",
       "     features_number  accuracy  f1_score  precision    recall  true_positives  \\\n",
       "0              48099  0.868873  0.864606   0.865588  0.863716            5977   \n",
       "1              32900  0.872286  0.869419   0.867375  0.872382            5829   \n",
       "2              36795  0.873162  0.870209   0.868315  0.872822            5849   \n",
       "3              40405  0.873687  0.870782   0.868830  0.873517            5847   \n",
       "4              47550  0.874475  0.871272   0.869888  0.872960            5896   \n",
       "5               4348  0.863708  0.861047   0.858698  0.865268            5724   \n",
       "6               7822  0.868610  0.866004   0.863641  0.870133            5758   \n",
       "7              32814  0.872024  0.868328   0.867958  0.868714            5938   \n",
       "8              36731  0.871148  0.867427   0.867058  0.867812            5933   \n",
       "9              40155  0.871236  0.867608   0.867007  0.868256            5922   \n",
       "10             47300  0.869748  0.865475   0.866568  0.864494            5986   \n",
       "11              4163  0.858368  0.854804   0.853401  0.856556            5798   \n",
       "12              7615  0.863095  0.859642   0.858232  0.861394            5826   \n",
       "13             24956  0.870886  0.868410   0.865979  0.872876            5758   \n",
       "14             32097  0.872637  0.869749   0.867742  0.872620            5835   \n",
       "15              3579  0.869660  0.867002   0.864685  0.870876            5775   \n",
       "16              5712  0.870536  0.867876   0.865569  0.871686            5783   \n",
       "17             28850  0.872899  0.870278   0.867962  0.874074            5798   \n",
       "18             36091  0.872637  0.869679   0.867777  0.872312            5845   \n",
       "19              3592  0.869048  0.866326   0.864058  0.870015            5779   \n",
       "20              6002  0.870798  0.868133   0.865834  0.871910            5786   \n",
       "21             39606  0.874125  0.871212   0.869285  0.873891            5852   \n",
       "22              4337  0.863708  0.861195   0.858790  0.865945            5702   \n",
       "23              7812  0.868610  0.866104   0.863685  0.870594            5743   \n",
       "24              4349  0.863445  0.860817   0.858452  0.865167            5717   \n",
       "25              7822  0.868697  0.866117   0.863738  0.870330            5755   \n",
       "26             24870  0.870886  0.867662   0.866155  0.869556            5866   \n",
       "27             32012  0.871324  0.867575   0.867290  0.867870            5938   \n",
       "28              3500  0.864758  0.861490   0.859828  0.863675            5817   \n",
       "29              5631  0.868172  0.865063   0.863259  0.867514            5826   \n",
       "..               ...       ...       ...        ...       ...             ...   \n",
       "609             5701  0.907563  0.904658   0.905261  0.904088            6181   \n",
       "610             3578  0.905287  0.902317   0.902889  0.901774            6167   \n",
       "611             5722  0.907213  0.904309   0.904857  0.903788            6177   \n",
       "612            28146  0.909664  0.906706   0.907889  0.905636            6213   \n",
       "613             3582  0.905200  0.902074   0.903348  0.900931            6191   \n",
       "614             5991  0.908263  0.905296   0.906298  0.904378            6199   \n",
       "615             3589  0.905375  0.902267   0.903482  0.901173            6190   \n",
       "616             5987  0.908001  0.905034   0.905991  0.904154            6196   \n",
       "617             4339  0.895571  0.892286   0.892884  0.891721            6113   \n",
       "618             7810  0.902574  0.899515   0.900097  0.898964            6152   \n",
       "619            24069  0.902836  0.899557   0.901175  0.898143            6189   \n",
       "620             3490  0.898897  0.895503   0.897027  0.894163            6164   \n",
       "621             5620  0.902486  0.899287   0.900478  0.898213            6173   \n",
       "622             3500  0.898985  0.895610   0.897059  0.894330            6162   \n",
       "623             5642  0.903536  0.900385   0.901520  0.899356            6177   \n",
       "624            28081  0.902223  0.898827   0.900907  0.897066            6200   \n",
       "625             3520  0.895833  0.892240   0.894174  0.890592            6160   \n",
       "626             5929  0.899947  0.896514   0.898387  0.894907            6181   \n",
       "627             3526  0.893645  0.889907   0.892137  0.888046            6157   \n",
       "628             5924  0.899860  0.896378   0.898462  0.894617            6187   \n",
       "629             4155  0.885329  0.881429   0.883096  0.879989            6093   \n",
       "630             7604  0.894695  0.891251   0.892375  0.890235            6127   \n",
       "631             3569  0.906250  0.903344   0.903768  0.902935            6167   \n",
       "632             5709  0.908876  0.906063   0.906437  0.905701            6180   \n",
       "633             3580  0.905287  0.902186   0.903356  0.901129            6188   \n",
       "634             5974  0.908613  0.905682   0.906568  0.904862            6197   \n",
       "635             3491  0.898284  0.894873   0.896380  0.893547            6160   \n",
       "636             5629  0.902924  0.899736   0.900943  0.898648            6176   \n",
       "637             3517  0.895833  0.892233   0.894199  0.890562            6161   \n",
       "638             5911  0.900385  0.896963   0.898855  0.895342            6184   \n",
       "\n",
       "     true_negatives  false_positives  false_negatives  \n",
       "0              3949              789              709  \n",
       "1              4136              602              857  \n",
       "2              4126              612              837  \n",
       "3              4134              604              839  \n",
       "4              4094              644              790  \n",
       "5              4143              595              962  \n",
       "6              4165              573              928  \n",
       "7              4024              714              748  \n",
       "8              4019              719              753  \n",
       "9              4031              707              764  \n",
       "10             3950              788              700  \n",
       "11             4008              730              888  \n",
       "12             4034              704              860  \n",
       "13             4191              547              928  \n",
       "14             4134              604              851  \n",
       "15             4160              578              911  \n",
       "16             4162              576              903  \n",
       "17             4174              564              888  \n",
       "18             4124              614              841  \n",
       "19             4149              589              907  \n",
       "20             4162              576              900  \n",
       "21             4134              604              834  \n",
       "22             4165              573              984  \n",
       "23             4180              558              943  \n",
       "24             4147              591              969  \n",
       "25             4169              569              931  \n",
       "26             4083              655              820  \n",
       "27             4016              722              748  \n",
       "28             4062              676              869  \n",
       "29             4092              646              860  \n",
       "..              ...              ...              ...  \n",
       "609            4187              551              505  \n",
       "610            4175              563              519  \n",
       "611            4187              551              509  \n",
       "612            4179              559              473  \n",
       "613            4150              588              495  \n",
       "614            4177              561              487  \n",
       "615            4153              585              496  \n",
       "616            4177              561              490  \n",
       "617            4118              620              573  \n",
       "618            4159              579              534  \n",
       "619            4125              613              497  \n",
       "620            4105              633              522  \n",
       "621            4137              601              513  \n",
       "622            4108              630              524  \n",
       "623            4145              593              509  \n",
       "624            4107              631              486  \n",
       "625            4074              664              526  \n",
       "626            4100              638              505  \n",
       "627            4052              686              529  \n",
       "628            4093              645              499  \n",
       "629            4021              717              593  \n",
       "630            4094              644              559  \n",
       "631            4186              552              519  \n",
       "632            4203              535              506  \n",
       "633            4154              584              498  \n",
       "634            4183              555              489  \n",
       "635            4102              636              526  \n",
       "636            4139              599              510  \n",
       "637            4073              665              525  \n",
       "638            4102              636              502  \n",
       "\n",
       "[639 rows x 11 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "639"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv('result_twitter_sa_combinations.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_tweets_df = results_df[results_df['clf_name'].str.contains('Reg_Log')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "213"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results_tweets_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_result = results_tweets_df.nsmallest(5, columns='accuracy')[['clf_name','comb','features_number','accuracy','f1_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clf_name</th>\n",
       "      <th>comb</th>\n",
       "      <th>features_number</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>Reg_Log_TF-IDF</td>\n",
       "      <td>('stop_words', 'pruning10')</td>\n",
       "      <td>4163</td>\n",
       "      <td>0.881127</td>\n",
       "      <td>0.877392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>Reg_Log_TF-IDF</td>\n",
       "      <td>('stop_words', 'urls', 'pruning10')</td>\n",
       "      <td>4152</td>\n",
       "      <td>0.881127</td>\n",
       "      <td>0.877338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>Reg_Log_TF-IDF</td>\n",
       "      <td>('stop_words', 'urls', 'norm_letters', 'pruning10')</td>\n",
       "      <td>4155</td>\n",
       "      <td>0.881653</td>\n",
       "      <td>0.877849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>Reg_Log_TF-IDF</td>\n",
       "      <td>('stop_words', 'norm_letters', 'pruning10')</td>\n",
       "      <td>4165</td>\n",
       "      <td>0.882003</td>\n",
       "      <td>0.878272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>Reg_Log_TF</td>\n",
       "      <td>('stop_words', 'pruning10')</td>\n",
       "      <td>4163</td>\n",
       "      <td>0.884891</td>\n",
       "      <td>0.881050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           clf_name                                                 comb  \\\n",
       "508  Reg_Log_TF-IDF                          ('stop_words', 'pruning10')   \n",
       "532  Reg_Log_TF-IDF                  ('stop_words', 'urls', 'pruning10')   \n",
       "558  Reg_Log_TF-IDF  ('stop_words', 'urls', 'norm_letters', 'pruning10')   \n",
       "534  Reg_Log_TF-IDF          ('stop_words', 'norm_letters', 'pruning10')   \n",
       "437      Reg_Log_TF                          ('stop_words', 'pruning10')   \n",
       "\n",
       "     features_number  accuracy  f1_score  \n",
       "508             4163  0.881127  0.877392  \n",
       "532             4152  0.881127  0.877338  \n",
       "558             4155  0.881653  0.877849  \n",
       "534             4165  0.882003  0.878272  \n",
       "437             4163  0.884891  0.881050  "
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_result.columns = ['Clf_Pon', 'Combinación', '# Car', 'Exact', 'V-F1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{|l|m{16em}|r|r|r|}\n",
      "\\toprule\n",
      "        Clf\\_Pon &                                          Combinación &  \\# Car &   Exact &    V-F1 \\\\\n",
      "\\midrule\n",
      " Reg\\_Log\\_TF-IDF &                          ('stop\\_words', 'pruning10') &   4163 &  0,8811 &  0,8774 \\\\\n",
      " Reg\\_Log\\_TF-IDF &                  ('stop\\_words', 'urls', 'pruning10') &   4152 &  0,8811 &  0,8773 \\\\\n",
      " Reg\\_Log\\_TF-IDF &  ('stop\\_words', 'urls', 'norm\\_letters', 'pruning10') &   4155 &  0,8817 &  0,8778 \\\\\n",
      " Reg\\_Log\\_TF-IDF &          ('stop\\_words', 'norm\\_letters', 'pruning10') &   4165 &  0,8820 &  0,8783 \\\\\n",
      "     Reg\\_Log\\_TF &                          ('stop\\_words', 'pruning10') &   4163 &  0,8849 &  0,8810 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(filter_result.round(4).to_latex(index=False, column_format='|l|m{16em}|r|r|r|', decimal=','))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_tg",
   "language": "python",
   "name": "python_tg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
